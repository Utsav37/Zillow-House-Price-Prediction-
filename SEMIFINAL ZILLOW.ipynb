{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "11351c034fced09083819214174fca1ab2b0b195"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "2304339f47a1d1585a3c81008c331c0e5d8017e3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SaleDollarCnt</th>\n",
       "      <th>PropertyID</th>\n",
       "      <th>censusblockgroup</th>\n",
       "      <th>Usecode</th>\n",
       "      <th>BedroomCnt</th>\n",
       "      <th>BathroomCnt</th>\n",
       "      <th>FinishedSquareFeet</th>\n",
       "      <th>GarageSquareFeet</th>\n",
       "      <th>LotSizeSquareFeet</th>\n",
       "      <th>StoryCnt</th>\n",
       "      <th>...</th>\n",
       "      <th>ZoneCodeCounty_UR</th>\n",
       "      <th>ZoneCodeCounty_URPSO</th>\n",
       "      <th>ZoneCodeCounty_UV</th>\n",
       "      <th>ZoneCodeCounty_UVEV</th>\n",
       "      <th>ZoneCodeCounty_WD II</th>\n",
       "      <th>Missing ViewType</th>\n",
       "      <th>Missing GarageSquareFeet</th>\n",
       "      <th>Missing BGMedYearBuilt</th>\n",
       "      <th>Missing BGMedRent</th>\n",
       "      <th>Missing BGMedHomeValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>285000.0</td>\n",
       "      <td>-0.397302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.633285</td>\n",
       "      <td>-0.375478</td>\n",
       "      <td>-0.320119</td>\n",
       "      <td>-0.049818</td>\n",
       "      <td>-0.197314</td>\n",
       "      <td>-1.012896</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062438</td>\n",
       "      <td>-0.087976</td>\n",
       "      <td>-0.077958</td>\n",
       "      <td>-0.058854</td>\n",
       "      <td>-0.013139</td>\n",
       "      <td>0.542108</td>\n",
       "      <td>-0.569910</td>\n",
       "      <td>-0.147578</td>\n",
       "      <td>-0.541975</td>\n",
       "      <td>-0.022761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>309950.0</td>\n",
       "      <td>-0.397299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.521924</td>\n",
       "      <td>-0.375478</td>\n",
       "      <td>-0.031915</td>\n",
       "      <td>-0.775699</td>\n",
       "      <td>-0.041773</td>\n",
       "      <td>-1.012896</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062438</td>\n",
       "      <td>-0.087976</td>\n",
       "      <td>-0.077958</td>\n",
       "      <td>-0.058854</td>\n",
       "      <td>-0.013139</td>\n",
       "      <td>-1.844651</td>\n",
       "      <td>-0.569910</td>\n",
       "      <td>-0.147578</td>\n",
       "      <td>-0.541975</td>\n",
       "      <td>-0.022761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>476000.0</td>\n",
       "      <td>-0.397296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.633285</td>\n",
       "      <td>-1.521526</td>\n",
       "      <td>-0.053264</td>\n",
       "      <td>0.449225</td>\n",
       "      <td>-0.220023</td>\n",
       "      <td>-1.012896</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062438</td>\n",
       "      <td>-0.087976</td>\n",
       "      <td>-0.077958</td>\n",
       "      <td>-0.058854</td>\n",
       "      <td>-0.013139</td>\n",
       "      <td>0.542108</td>\n",
       "      <td>-0.569910</td>\n",
       "      <td>-0.147578</td>\n",
       "      <td>-0.541975</td>\n",
       "      <td>-0.022761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>324950.0</td>\n",
       "      <td>-0.397295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.633285</td>\n",
       "      <td>-0.088966</td>\n",
       "      <td>0.384379</td>\n",
       "      <td>-0.514406</td>\n",
       "      <td>-0.005720</td>\n",
       "      <td>-1.012896</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062438</td>\n",
       "      <td>-0.087976</td>\n",
       "      <td>-0.077958</td>\n",
       "      <td>-0.058854</td>\n",
       "      <td>-0.013139</td>\n",
       "      <td>-1.844651</td>\n",
       "      <td>1.754664</td>\n",
       "      <td>-0.147578</td>\n",
       "      <td>-0.541975</td>\n",
       "      <td>-0.022761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>325000.0</td>\n",
       "      <td>-0.397294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.633285</td>\n",
       "      <td>-0.661990</td>\n",
       "      <td>-0.512255</td>\n",
       "      <td>-0.357126</td>\n",
       "      <td>-0.170997</td>\n",
       "      <td>0.903396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062438</td>\n",
       "      <td>-0.087976</td>\n",
       "      <td>-0.077958</td>\n",
       "      <td>-0.058854</td>\n",
       "      <td>-0.013139</td>\n",
       "      <td>-1.844651</td>\n",
       "      <td>1.754664</td>\n",
       "      <td>-0.147578</td>\n",
       "      <td>-0.541975</td>\n",
       "      <td>-0.022761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 211 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SaleDollarCnt  PropertyID  censusblockgroup  Usecode  BedroomCnt  \\\n",
       "0       285000.0   -0.397302               0.0      0.0    0.633285   \n",
       "1       309950.0   -0.397299               0.0      0.0   -0.521924   \n",
       "2       476000.0   -0.397296               0.0      0.0    0.633285   \n",
       "3       324950.0   -0.397295               0.0      0.0    0.633285   \n",
       "4       325000.0   -0.397294               0.0      0.0    0.633285   \n",
       "\n",
       "   BathroomCnt  FinishedSquareFeet  GarageSquareFeet  LotSizeSquareFeet  \\\n",
       "0    -0.375478           -0.320119         -0.049818          -0.197314   \n",
       "1    -0.375478           -0.031915         -0.775699          -0.041773   \n",
       "2    -1.521526           -0.053264          0.449225          -0.220023   \n",
       "3    -0.088966            0.384379         -0.514406          -0.005720   \n",
       "4    -0.661990           -0.512255         -0.357126          -0.170997   \n",
       "\n",
       "   StoryCnt           ...            ZoneCodeCounty_UR  ZoneCodeCounty_URPSO  \\\n",
       "0 -1.012896           ...                    -0.062438             -0.087976   \n",
       "1 -1.012896           ...                    -0.062438             -0.087976   \n",
       "2 -1.012896           ...                    -0.062438             -0.087976   \n",
       "3 -1.012896           ...                    -0.062438             -0.087976   \n",
       "4  0.903396           ...                    -0.062438             -0.087976   \n",
       "\n",
       "   ZoneCodeCounty_UV  ZoneCodeCounty_UVEV  ZoneCodeCounty_WD II  \\\n",
       "0          -0.077958            -0.058854             -0.013139   \n",
       "1          -0.077958            -0.058854             -0.013139   \n",
       "2          -0.077958            -0.058854             -0.013139   \n",
       "3          -0.077958            -0.058854             -0.013139   \n",
       "4          -0.077958            -0.058854             -0.013139   \n",
       "\n",
       "   Missing ViewType  Missing GarageSquareFeet  Missing BGMedYearBuilt  \\\n",
       "0          0.542108                 -0.569910               -0.147578   \n",
       "1         -1.844651                 -0.569910               -0.147578   \n",
       "2          0.542108                 -0.569910               -0.147578   \n",
       "3         -1.844651                  1.754664               -0.147578   \n",
       "4         -1.844651                  1.754664               -0.147578   \n",
       "\n",
       "   Missing BGMedRent  Missing BGMedHomeValue  \n",
       "0          -0.541975               -0.022761  \n",
       "1          -0.541975               -0.022761  \n",
       "2          -0.541975               -0.022761  \n",
       "3          -0.541975               -0.022761  \n",
       "4          -0.541975               -0.022761  \n",
       "\n",
       "[5 rows x 211 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"final_train_5.csv\")\n",
    "df=df.drop(\"Unnamed: 0\",1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "793d383a324c4f359574c5a1b9d69b975e868766"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PropertyID</th>\n",
       "      <th>censusblockgroup</th>\n",
       "      <th>Usecode</th>\n",
       "      <th>BedroomCnt</th>\n",
       "      <th>BathroomCnt</th>\n",
       "      <th>FinishedSquareFeet</th>\n",
       "      <th>GarageSquareFeet</th>\n",
       "      <th>LotSizeSquareFeet</th>\n",
       "      <th>StoryCnt</th>\n",
       "      <th>BuiltYear</th>\n",
       "      <th>...</th>\n",
       "      <th>ZoneCodeCounty_UR</th>\n",
       "      <th>ZoneCodeCounty_URPSO</th>\n",
       "      <th>ZoneCodeCounty_UV</th>\n",
       "      <th>ZoneCodeCounty_UVEV</th>\n",
       "      <th>ZoneCodeCounty_WD II</th>\n",
       "      <th>Missing ViewType</th>\n",
       "      <th>Missing GarageSquareFeet</th>\n",
       "      <th>Missing BGMedYearBuilt</th>\n",
       "      <th>Missing BGMedRent</th>\n",
       "      <th>Missing BGMedHomeValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.397302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.633285</td>\n",
       "      <td>-0.375478</td>\n",
       "      <td>-0.320119</td>\n",
       "      <td>-0.049818</td>\n",
       "      <td>-0.197314</td>\n",
       "      <td>-1.012896</td>\n",
       "      <td>-0.371555</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062438</td>\n",
       "      <td>-0.087976</td>\n",
       "      <td>-0.077958</td>\n",
       "      <td>-0.058854</td>\n",
       "      <td>-0.013139</td>\n",
       "      <td>0.542108</td>\n",
       "      <td>-0.569910</td>\n",
       "      <td>-0.147578</td>\n",
       "      <td>-0.541975</td>\n",
       "      <td>-0.022761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.397299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.521924</td>\n",
       "      <td>-0.375478</td>\n",
       "      <td>-0.031915</td>\n",
       "      <td>-0.775699</td>\n",
       "      <td>-0.041773</td>\n",
       "      <td>-1.012896</td>\n",
       "      <td>-0.799322</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062438</td>\n",
       "      <td>-0.087976</td>\n",
       "      <td>-0.077958</td>\n",
       "      <td>-0.058854</td>\n",
       "      <td>-0.013139</td>\n",
       "      <td>-1.844651</td>\n",
       "      <td>-0.569910</td>\n",
       "      <td>-0.147578</td>\n",
       "      <td>-0.541975</td>\n",
       "      <td>-0.022761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.397296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.633285</td>\n",
       "      <td>-1.521526</td>\n",
       "      <td>-0.053264</td>\n",
       "      <td>0.449225</td>\n",
       "      <td>-0.220023</td>\n",
       "      <td>-1.012896</td>\n",
       "      <td>-0.728028</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062438</td>\n",
       "      <td>-0.087976</td>\n",
       "      <td>-0.077958</td>\n",
       "      <td>-0.058854</td>\n",
       "      <td>-0.013139</td>\n",
       "      <td>0.542108</td>\n",
       "      <td>-0.569910</td>\n",
       "      <td>-0.147578</td>\n",
       "      <td>-0.541975</td>\n",
       "      <td>-0.022761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.397295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.633285</td>\n",
       "      <td>-0.088966</td>\n",
       "      <td>0.384379</td>\n",
       "      <td>-0.514406</td>\n",
       "      <td>-0.005720</td>\n",
       "      <td>-1.012896</td>\n",
       "      <td>-0.478497</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062438</td>\n",
       "      <td>-0.087976</td>\n",
       "      <td>-0.077958</td>\n",
       "      <td>-0.058854</td>\n",
       "      <td>-0.013139</td>\n",
       "      <td>-1.844651</td>\n",
       "      <td>1.754664</td>\n",
       "      <td>-0.147578</td>\n",
       "      <td>-0.541975</td>\n",
       "      <td>-0.022761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.397294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.633285</td>\n",
       "      <td>-0.661990</td>\n",
       "      <td>-0.512255</td>\n",
       "      <td>-0.357126</td>\n",
       "      <td>-0.170997</td>\n",
       "      <td>0.903396</td>\n",
       "      <td>-0.977559</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062438</td>\n",
       "      <td>-0.087976</td>\n",
       "      <td>-0.077958</td>\n",
       "      <td>-0.058854</td>\n",
       "      <td>-0.013139</td>\n",
       "      <td>-1.844651</td>\n",
       "      <td>1.754664</td>\n",
       "      <td>-0.147578</td>\n",
       "      <td>-0.541975</td>\n",
       "      <td>-0.022761</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 210 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PropertyID  censusblockgroup  Usecode  BedroomCnt  BathroomCnt  \\\n",
       "0   -0.397302               0.0      0.0    0.633285    -0.375478   \n",
       "1   -0.397299               0.0      0.0   -0.521924    -0.375478   \n",
       "2   -0.397296               0.0      0.0    0.633285    -1.521526   \n",
       "3   -0.397295               0.0      0.0    0.633285    -0.088966   \n",
       "4   -0.397294               0.0      0.0    0.633285    -0.661990   \n",
       "\n",
       "   FinishedSquareFeet  GarageSquareFeet  LotSizeSquareFeet  StoryCnt  \\\n",
       "0           -0.320119         -0.049818          -0.197314 -1.012896   \n",
       "1           -0.031915         -0.775699          -0.041773 -1.012896   \n",
       "2           -0.053264          0.449225          -0.220023 -1.012896   \n",
       "3            0.384379         -0.514406          -0.005720 -1.012896   \n",
       "4           -0.512255         -0.357126          -0.170997  0.903396   \n",
       "\n",
       "   BuiltYear           ...            ZoneCodeCounty_UR  ZoneCodeCounty_URPSO  \\\n",
       "0  -0.371555           ...                    -0.062438             -0.087976   \n",
       "1  -0.799322           ...                    -0.062438             -0.087976   \n",
       "2  -0.728028           ...                    -0.062438             -0.087976   \n",
       "3  -0.478497           ...                    -0.062438             -0.087976   \n",
       "4  -0.977559           ...                    -0.062438             -0.087976   \n",
       "\n",
       "   ZoneCodeCounty_UV  ZoneCodeCounty_UVEV  ZoneCodeCounty_WD II  \\\n",
       "0          -0.077958            -0.058854             -0.013139   \n",
       "1          -0.077958            -0.058854             -0.013139   \n",
       "2          -0.077958            -0.058854             -0.013139   \n",
       "3          -0.077958            -0.058854             -0.013139   \n",
       "4          -0.077958            -0.058854             -0.013139   \n",
       "\n",
       "   Missing ViewType  Missing GarageSquareFeet  Missing BGMedYearBuilt  \\\n",
       "0          0.542108                 -0.569910               -0.147578   \n",
       "1         -1.844651                 -0.569910               -0.147578   \n",
       "2          0.542108                 -0.569910               -0.147578   \n",
       "3         -1.844651                  1.754664               -0.147578   \n",
       "4         -1.844651                  1.754664               -0.147578   \n",
       "\n",
       "   Missing BGMedRent  Missing BGMedHomeValue  \n",
       "0          -0.541975               -0.022761  \n",
       "1          -0.541975               -0.022761  \n",
       "2          -0.541975               -0.022761  \n",
       "3          -0.541975               -0.022761  \n",
       "4          -0.541975               -0.022761  \n",
       "\n",
       "[5 rows x 210 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:,1:]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "265d4cc7e04f58ede3dc264bd157b50a6807859f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SaleDollarCnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>285000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>309950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>476000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>324950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>325000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SaleDollarCnt\n",
       "0       285000.0\n",
       "1       309950.0\n",
       "2       476000.0\n",
       "3       324950.0\n",
       "4       325000.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.DataFrame(df.iloc[:,0])\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4ef58336ef9b86cd14c10dacc5b7744b4dccfc57"
   },
   "source": [
    "# LightGBM Final Models:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "0d0113fdd21eefacb333af3cb21621fa5fe650ee"
   },
   "outputs": [],
   "source": [
    "def cross_validation_function3(X,y,model,fold):\n",
    "    size=int(len(X)/fold)\n",
    "    l=0\n",
    "    u=size\n",
    "    scores=[]\n",
    "    for f in range(fold):\n",
    "#         print(\"l =\",l,\"u =\",u,\"\")\n",
    "        dfxtest=X.iloc[l:u,:]\n",
    "        dfytest=y.iloc[l:u,:]\n",
    "        dfxtrain=X.drop(X.iloc[l:u].index,axis=0)\n",
    "        dfytrain=y.drop(X.iloc[l:u].index,axis=0)\n",
    "        model.fit(dfxtrain,dfytrain.values.ravel())\n",
    "        y_pred=model.predict(dfxtest)\n",
    "        y_true=pd.Series(dfytest.iloc[:,0])\n",
    "#         pd.Series(y.iloc[:,0])\n",
    "#         print(y_true)\n",
    "#         print(y_pred)\n",
    "        scores.append(np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "#         print(\"        FOLD \",f)\n",
    "#         print(\"        --> Score :\", (np.mean(np.abs((y_true - y_pred) / y_true))))\n",
    "        l=l+size\n",
    "        u=u+size\n",
    "    print(\"Final score is: \",np.mean(scores))\n",
    "    return np.mean(scores)\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "60f18f4eb6dde3d91f5a357701c34c6931350f10"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:116: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.09383405657467478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:116: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:116: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:116: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:116: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:116: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score is:  0.13037873681970596\n",
      "Testing Cross Validation Error:  0.13037873681970596\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "import numpy as np\n",
    "model = LGBMRegressor(num_iterations=900,boosting_type='dart', max_depth=7, learning_rate=0.08, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = LGBMRegressor(num_iterations=900,boosting_type='dart', max_depth=7, learning_rate=0.08, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "newscore=cross_validation_function3(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_function5(X,y,model,fold):\n",
    "    size=int(len(X)/fold)\n",
    "    l=0\n",
    "    u=size\n",
    "    scores=[]\n",
    "    mainlist=[]\n",
    "    for f in range(fold):\n",
    "#         print(\"l =\",l,\"u =\",u,\"\")\n",
    "        dfxtest=X.iloc[l:u,:]\n",
    "        dfytest=y.iloc[l:u,:]\n",
    "        dfxtrain=X.drop(X.iloc[l:u].index,axis=0)\n",
    "        dfytrain=y.drop(X.iloc[l:u].index,axis=0)\n",
    "        model.fit(dfxtrain,dfytrain.values.ravel())\n",
    "        y_pred=model.predict(dfxtest)\n",
    "        templist=list(y_pred)\n",
    "        mainlist=mainlist + templist\n",
    "        y_true=pd.Series(dfytest.iloc[:,0])\n",
    "#         pd.Series(y.iloc[:,0])\n",
    "#         print(y_true)\n",
    "#         print(y_pred)\n",
    "        scores.append(np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "#         print(\"        FOLD \",f)\n",
    "#         print(\"        --> Score :\", (np.mean(np.abs((y_true - y_pred) / y_true))))\n",
    "        l=l+size\n",
    "        u=u+size\n",
    "    print(\"Final score is: \",np.mean(scores))\n",
    "    return np.mean(scores),mainlist\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_uuid": "00cd5ab712607ad00ba7a38482407ab93bc171d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.0910829674581461\n",
      "Final score is:  0.13003222743241366\n",
      "Testing Cross Validation Error:  0.13003222743241366\n"
     ]
    }
   ],
   "source": [
    "# 5    #### 1 star @@@@@\n",
    "from lightgbm import LGBMRegressor\n",
    "import numpy as np\n",
    "model = LGBMRegressor(boosting_type='dart', max_depth=8, learning_rate=0.13, n_estimators=600,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = LGBMRegressor(boosting_type='dart', max_depth=8, learning_rate=0.13, n_estimators=600,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "newscore,newprediction1=cross_validation_function5(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "maindf=pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>262521.878520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>332928.985356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>490602.175458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>342448.554500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>305932.030521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model 1\n",
       "0  262521.878520\n",
       "1  332928.985356\n",
       "2  490602.175458\n",
       "3  342448.554500\n",
       "4  305932.030521"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maindf[\"Model 1\"]=newprediction1\n",
    "maindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.09173034223345002\n",
      "Final score is:  0.1294838650847539\n",
      "Testing Cross Validation Error:  0.1294838650847539\n"
     ]
    }
   ],
   "source": [
    "# 12   ^^^^^  2 star   ^^^^^^\n",
    "from lightgbm import LGBMRegressor\n",
    "import numpy as np\n",
    "model = LGBMRegressor(boosting_type='dart', max_depth=9, learning_rate=0.19, n_estimators=400,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = LGBMRegressor(boosting_type='dart', max_depth=9, learning_rate=0.19, n_estimators=400,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "newscore,newprediction2=cross_validation_function5(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.08780665488601577\n",
      "Final score is:  0.1301254008919178\n",
      "Testing Cross Validation Error:  0.1301254008919178\n"
     ]
    }
   ],
   "source": [
    "# 11     ########## 3 star ##########\n",
    "from lightgbm import LGBMRegressor\n",
    "import numpy as np\n",
    "model = LGBMRegressor(boosting_type='dart', max_depth=8, learning_rate=0.24, n_estimators=350,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = LGBMRegressor(boosting_type='dart', max_depth=8, learning_rate=0.24, n_estimators=350,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "newscore,newprediction3=cross_validation_function5(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:116: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.09118468888695819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:116: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:116: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:116: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:116: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:116: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score is:  0.1301376781265132\n",
      "Testing Cross Validation Error:  0.1301376781265132\n"
     ]
    }
   ],
   "source": [
    "# 4              ###### 4 star $$$$$$\n",
    "model = LGBMRegressor(boosting_type='dart',num_iterations=900 ,max_depth=7, learning_rate=0.09, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = LGBMRegressor(boosting_type='dart',num_iterations=900 ,max_depth=7, learning_rate=0.09, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "newscore,newprediction4=cross_validation_function5(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.0906421739064629\n",
      "Final score is:  0.12912559913782506\n",
      "Testing Cross Validation Error:  0.12912559913782506\n"
     ]
    }
   ],
   "source": [
    "# 25      %%% 5  star %%%%\n",
    "\n",
    "model = LGBMRegressor(boosting_type='dart', num_leaves=29,min_data_in_leaf=15 ,max_depth=7, learning_rate=0.09, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = LGBMRegressor(boosting_type='dart', num_leaves=29,min_data_in_leaf=15 ,max_depth=7, learning_rate=0.09, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "newscore,newprediction5=cross_validation_function5(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.08639806154333846\n",
      "Final score is:  0.12946930176990257\n",
      "Testing Cross Validation Error:  0.12946930176990257\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 22     ######6 star$$$$$$$$$\n",
    "\n",
    "model = LGBMRegressor(boosting_type='dart', num_leaves=25, max_depth=7, learning_rate=0.13, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = LGBMRegressor(boosting_type='dart', num_leaves=25, max_depth=7, learning_rate=0.13, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "newscore,newprediction6=cross_validation_function5(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.07584326247482823\n",
      "Final score is:  0.133919734864522\n",
      "Testing Cross Validation Error:  0.133919734864522\n"
     ]
    }
   ],
   "source": [
    "# 16--Final Gradient Booster ALone   ##### 7 star #####\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score  \n",
    "model = ensemble.GradientBoostingRegressor(n_estimators= 300, max_depth=7,learning_rate=0.054 , loss= 'ls',random_state=30)\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = ensemble.GradientBoostingRegressor(n_estimators= 300, max_depth=7,learning_rate=0.054 , loss= 'ls',random_state=30)\n",
    "newscore,newprediction7=cross_validation_function5(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)\n",
    "\n",
    "\n",
    "              \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.06381928266400659\n",
      "Final score is:  0.13411487443671416\n",
      "Testing Cross Validation Error:  0.13411487443671416\n"
     ]
    }
   ],
   "source": [
    "# Zillow 1.4$   ##### 8 star #####\n",
    "model = XGBRegressor(max_depth=8,learning_rate=0.04, n_estimators=500,booster='gbtree',random_state=30)\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = XGBRegressor(max_depth=8,learning_rate=0.04, n_estimators=500,booster='gbtree',random_state=30)\n",
    "newscore,newprediction8=cross_validation_function5(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.07988238944609445\n",
      "Final score is:  0.13469952012166053\n",
      "Testing Cross Validation Error:  0.13469952012166053\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Zillow 1.4$##   ##### 9 star #####\n",
    "model = XGBRegressor(max_depth=8,learning_rate=0.081, n_estimators=100,booster='gbtree',random_state=30)\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = XGBRegressor(max_depth=8,learning_rate=0.081, n_estimators=100,booster='gbtree',random_state=30)\n",
    "newscore,newprediction9=cross_validation_function5(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.05291163508976431\n",
      "Final score is:  0.14433978908042905\n",
      "Testing Cross Validation Error:  0.14433978908042905\n"
     ]
    }
   ],
   "source": [
    "# Zillow -----> ##### 10 star #####\n",
    "model = RandomForestRegressor(max_depth=18, random_state=30,n_estimators=91)\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = RandomForestRegressor(max_depth=18, random_state=30,n_estimators=91)\n",
    "newscore,newprediction10=cross_validation_function5(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model 1</th>\n",
       "      <th>Model 2</th>\n",
       "      <th>Model 3</th>\n",
       "      <th>Model 4</th>\n",
       "      <th>Model 5</th>\n",
       "      <th>Model 6</th>\n",
       "      <th>Model 7</th>\n",
       "      <th>Model 8</th>\n",
       "      <th>Model 9</th>\n",
       "      <th>Model 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>262521.878520</td>\n",
       "      <td>255326.401497</td>\n",
       "      <td>260132.800960</td>\n",
       "      <td>262287.383701</td>\n",
       "      <td>260219.968623</td>\n",
       "      <td>263179.585892</td>\n",
       "      <td>263121.673757</td>\n",
       "      <td>258759.75000</td>\n",
       "      <td>257875.09375</td>\n",
       "      <td>281089.981962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>332928.985356</td>\n",
       "      <td>315633.720081</td>\n",
       "      <td>322205.082089</td>\n",
       "      <td>325354.683470</td>\n",
       "      <td>322101.929533</td>\n",
       "      <td>309633.844363</td>\n",
       "      <td>340416.785533</td>\n",
       "      <td>319191.68750</td>\n",
       "      <td>336675.40625</td>\n",
       "      <td>352975.002584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>490602.175458</td>\n",
       "      <td>481046.483351</td>\n",
       "      <td>487062.807700</td>\n",
       "      <td>474635.051386</td>\n",
       "      <td>488908.086621</td>\n",
       "      <td>498633.683838</td>\n",
       "      <td>535588.582278</td>\n",
       "      <td>515659.00000</td>\n",
       "      <td>518264.93750</td>\n",
       "      <td>563381.119324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>342448.554500</td>\n",
       "      <td>352571.162562</td>\n",
       "      <td>333338.046314</td>\n",
       "      <td>353287.601711</td>\n",
       "      <td>342887.897821</td>\n",
       "      <td>346680.052506</td>\n",
       "      <td>330273.702360</td>\n",
       "      <td>323240.62500</td>\n",
       "      <td>345656.93750</td>\n",
       "      <td>378295.022702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>305932.030521</td>\n",
       "      <td>289842.010467</td>\n",
       "      <td>314063.619298</td>\n",
       "      <td>311320.346878</td>\n",
       "      <td>306490.238979</td>\n",
       "      <td>308895.932337</td>\n",
       "      <td>320440.796837</td>\n",
       "      <td>312079.84375</td>\n",
       "      <td>315151.65625</td>\n",
       "      <td>351184.629669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model 1        Model 2        Model 3        Model 4        Model 5  \\\n",
       "0  262521.878520  255326.401497  260132.800960  262287.383701  260219.968623   \n",
       "1  332928.985356  315633.720081  322205.082089  325354.683470  322101.929533   \n",
       "2  490602.175458  481046.483351  487062.807700  474635.051386  488908.086621   \n",
       "3  342448.554500  352571.162562  333338.046314  353287.601711  342887.897821   \n",
       "4  305932.030521  289842.010467  314063.619298  311320.346878  306490.238979   \n",
       "\n",
       "         Model 6        Model 7       Model 8       Model 9       Model 10  \n",
       "0  263179.585892  263121.673757  258759.75000  257875.09375  281089.981962  \n",
       "1  309633.844363  340416.785533  319191.68750  336675.40625  352975.002584  \n",
       "2  498633.683838  535588.582278  515659.00000  518264.93750  563381.119324  \n",
       "3  346680.052506  330273.702360  323240.62500  345656.93750  378295.022702  \n",
       "4  308895.932337  320440.796837  312079.84375  315151.65625  351184.629669  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maindf[\"Model 1\"]=newprediction1\n",
    "maindf[\"Model 2\"]=newprediction2\n",
    "maindf[\"Model 3\"]=newprediction3\n",
    "maindf[\"Model 4\"]=newprediction4\n",
    "maindf[\"Model 5\"]=newprediction5\n",
    "maindf[\"Model 6\"]=newprediction6\n",
    "maindf[\"Model 7\"]=newprediction7\n",
    "maindf[\"Model 8\"]=newprediction8\n",
    "maindf[\"Model 9\"]=newprediction9\n",
    "maindf[\"Model 10\"]=newprediction10\n",
    "\n",
    "maindf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "maindf.insert(loc=0, column='y', value=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>Model 1</th>\n",
       "      <th>Model 2</th>\n",
       "      <th>Model 3</th>\n",
       "      <th>Model 4</th>\n",
       "      <th>Model 5</th>\n",
       "      <th>Model 6</th>\n",
       "      <th>Model 7</th>\n",
       "      <th>Model 8</th>\n",
       "      <th>Model 9</th>\n",
       "      <th>Model 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>285000.0</td>\n",
       "      <td>262521.878520</td>\n",
       "      <td>255326.401497</td>\n",
       "      <td>260132.800960</td>\n",
       "      <td>262287.383701</td>\n",
       "      <td>260219.968623</td>\n",
       "      <td>263179.585892</td>\n",
       "      <td>263121.673757</td>\n",
       "      <td>258759.75000</td>\n",
       "      <td>257875.09375</td>\n",
       "      <td>281089.981962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>309950.0</td>\n",
       "      <td>332928.985356</td>\n",
       "      <td>315633.720081</td>\n",
       "      <td>322205.082089</td>\n",
       "      <td>325354.683470</td>\n",
       "      <td>322101.929533</td>\n",
       "      <td>309633.844363</td>\n",
       "      <td>340416.785533</td>\n",
       "      <td>319191.68750</td>\n",
       "      <td>336675.40625</td>\n",
       "      <td>352975.002584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>476000.0</td>\n",
       "      <td>490602.175458</td>\n",
       "      <td>481046.483351</td>\n",
       "      <td>487062.807700</td>\n",
       "      <td>474635.051386</td>\n",
       "      <td>488908.086621</td>\n",
       "      <td>498633.683838</td>\n",
       "      <td>535588.582278</td>\n",
       "      <td>515659.00000</td>\n",
       "      <td>518264.93750</td>\n",
       "      <td>563381.119324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>324950.0</td>\n",
       "      <td>342448.554500</td>\n",
       "      <td>352571.162562</td>\n",
       "      <td>333338.046314</td>\n",
       "      <td>353287.601711</td>\n",
       "      <td>342887.897821</td>\n",
       "      <td>346680.052506</td>\n",
       "      <td>330273.702360</td>\n",
       "      <td>323240.62500</td>\n",
       "      <td>345656.93750</td>\n",
       "      <td>378295.022702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>325000.0</td>\n",
       "      <td>305932.030521</td>\n",
       "      <td>289842.010467</td>\n",
       "      <td>314063.619298</td>\n",
       "      <td>311320.346878</td>\n",
       "      <td>306490.238979</td>\n",
       "      <td>308895.932337</td>\n",
       "      <td>320440.796837</td>\n",
       "      <td>312079.84375</td>\n",
       "      <td>315151.65625</td>\n",
       "      <td>351184.629669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>235000.0</td>\n",
       "      <td>272752.681107</td>\n",
       "      <td>269312.615583</td>\n",
       "      <td>276245.691434</td>\n",
       "      <td>280523.589189</td>\n",
       "      <td>273453.651624</td>\n",
       "      <td>270881.107695</td>\n",
       "      <td>279287.818052</td>\n",
       "      <td>289651.15625</td>\n",
       "      <td>292718.31250</td>\n",
       "      <td>299094.880491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>653295.0</td>\n",
       "      <td>585881.963233</td>\n",
       "      <td>553185.387005</td>\n",
       "      <td>563095.660713</td>\n",
       "      <td>579316.132379</td>\n",
       "      <td>574940.572297</td>\n",
       "      <td>571162.390259</td>\n",
       "      <td>622298.972842</td>\n",
       "      <td>618828.43750</td>\n",
       "      <td>641031.18750</td>\n",
       "      <td>652416.316586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>370000.0</td>\n",
       "      <td>397330.304246</td>\n",
       "      <td>372078.594993</td>\n",
       "      <td>343953.062185</td>\n",
       "      <td>367264.176228</td>\n",
       "      <td>363194.117264</td>\n",
       "      <td>346464.228644</td>\n",
       "      <td>420785.757512</td>\n",
       "      <td>347469.50000</td>\n",
       "      <td>354420.46875</td>\n",
       "      <td>332381.884085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>334950.0</td>\n",
       "      <td>259620.651275</td>\n",
       "      <td>268349.600280</td>\n",
       "      <td>258949.233070</td>\n",
       "      <td>267060.588909</td>\n",
       "      <td>265065.518003</td>\n",
       "      <td>260267.238947</td>\n",
       "      <td>245933.313170</td>\n",
       "      <td>227614.96875</td>\n",
       "      <td>275968.71875</td>\n",
       "      <td>302956.600612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>625000.0</td>\n",
       "      <td>579692.710000</td>\n",
       "      <td>583867.565807</td>\n",
       "      <td>587678.424641</td>\n",
       "      <td>580253.970998</td>\n",
       "      <td>573871.958624</td>\n",
       "      <td>567366.245256</td>\n",
       "      <td>618893.239209</td>\n",
       "      <td>617565.56250</td>\n",
       "      <td>624878.75000</td>\n",
       "      <td>659900.964584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          y        Model 1        Model 2        Model 3        Model 4  \\\n",
       "0  285000.0  262521.878520  255326.401497  260132.800960  262287.383701   \n",
       "1  309950.0  332928.985356  315633.720081  322205.082089  325354.683470   \n",
       "2  476000.0  490602.175458  481046.483351  487062.807700  474635.051386   \n",
       "3  324950.0  342448.554500  352571.162562  333338.046314  353287.601711   \n",
       "4  325000.0  305932.030521  289842.010467  314063.619298  311320.346878   \n",
       "5  235000.0  272752.681107  269312.615583  276245.691434  280523.589189   \n",
       "6  653295.0  585881.963233  553185.387005  563095.660713  579316.132379   \n",
       "7  370000.0  397330.304246  372078.594993  343953.062185  367264.176228   \n",
       "8  334950.0  259620.651275  268349.600280  258949.233070  267060.588909   \n",
       "9  625000.0  579692.710000  583867.565807  587678.424641  580253.970998   \n",
       "\n",
       "         Model 5        Model 6        Model 7       Model 8       Model 9  \\\n",
       "0  260219.968623  263179.585892  263121.673757  258759.75000  257875.09375   \n",
       "1  322101.929533  309633.844363  340416.785533  319191.68750  336675.40625   \n",
       "2  488908.086621  498633.683838  535588.582278  515659.00000  518264.93750   \n",
       "3  342887.897821  346680.052506  330273.702360  323240.62500  345656.93750   \n",
       "4  306490.238979  308895.932337  320440.796837  312079.84375  315151.65625   \n",
       "5  273453.651624  270881.107695  279287.818052  289651.15625  292718.31250   \n",
       "6  574940.572297  571162.390259  622298.972842  618828.43750  641031.18750   \n",
       "7  363194.117264  346464.228644  420785.757512  347469.50000  354420.46875   \n",
       "8  265065.518003  260267.238947  245933.313170  227614.96875  275968.71875   \n",
       "9  573871.958624  567366.245256  618893.239209  617565.56250  624878.75000   \n",
       "\n",
       "        Model 10  \n",
       "0  281089.981962  \n",
       "1  352975.002584  \n",
       "2  563381.119324  \n",
       "3  378295.022702  \n",
       "4  351184.629669  \n",
       "5  299094.880491  \n",
       "6  652416.316586  \n",
       "7  332381.884085  \n",
       "8  302956.600612  \n",
       "9  659900.964584  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maindf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>Model 1</th>\n",
       "      <th>Model 2</th>\n",
       "      <th>Model 3</th>\n",
       "      <th>Model 4</th>\n",
       "      <th>Model 5</th>\n",
       "      <th>Model 6</th>\n",
       "      <th>Model 7</th>\n",
       "      <th>Model 8</th>\n",
       "      <th>Model 9</th>\n",
       "      <th>Model 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.902615</td>\n",
       "      <td>0.902313</td>\n",
       "      <td>0.903493</td>\n",
       "      <td>0.902737</td>\n",
       "      <td>0.901657</td>\n",
       "      <td>0.903730</td>\n",
       "      <td>0.892681</td>\n",
       "      <td>0.888974</td>\n",
       "      <td>0.891214</td>\n",
       "      <td>0.893118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 1</th>\n",
       "      <td>0.902615</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997024</td>\n",
       "      <td>0.996247</td>\n",
       "      <td>0.997808</td>\n",
       "      <td>0.996032</td>\n",
       "      <td>0.996784</td>\n",
       "      <td>0.980612</td>\n",
       "      <td>0.971332</td>\n",
       "      <td>0.973502</td>\n",
       "      <td>0.978185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 2</th>\n",
       "      <td>0.902313</td>\n",
       "      <td>0.997024</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996003</td>\n",
       "      <td>0.996968</td>\n",
       "      <td>0.995125</td>\n",
       "      <td>0.996271</td>\n",
       "      <td>0.980882</td>\n",
       "      <td>0.972258</td>\n",
       "      <td>0.974200</td>\n",
       "      <td>0.978884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 3</th>\n",
       "      <td>0.903493</td>\n",
       "      <td>0.996247</td>\n",
       "      <td>0.996003</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996353</td>\n",
       "      <td>0.994586</td>\n",
       "      <td>0.996167</td>\n",
       "      <td>0.979530</td>\n",
       "      <td>0.971437</td>\n",
       "      <td>0.973341</td>\n",
       "      <td>0.977717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 4</th>\n",
       "      <td>0.902737</td>\n",
       "      <td>0.997808</td>\n",
       "      <td>0.996968</td>\n",
       "      <td>0.996353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996068</td>\n",
       "      <td>0.996968</td>\n",
       "      <td>0.980352</td>\n",
       "      <td>0.971513</td>\n",
       "      <td>0.973611</td>\n",
       "      <td>0.978701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 5</th>\n",
       "      <td>0.901657</td>\n",
       "      <td>0.996032</td>\n",
       "      <td>0.995125</td>\n",
       "      <td>0.994586</td>\n",
       "      <td>0.996068</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995711</td>\n",
       "      <td>0.980078</td>\n",
       "      <td>0.971552</td>\n",
       "      <td>0.974032</td>\n",
       "      <td>0.977760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 6</th>\n",
       "      <td>0.903730</td>\n",
       "      <td>0.996784</td>\n",
       "      <td>0.996271</td>\n",
       "      <td>0.996167</td>\n",
       "      <td>0.996968</td>\n",
       "      <td>0.995711</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.979179</td>\n",
       "      <td>0.970682</td>\n",
       "      <td>0.972447</td>\n",
       "      <td>0.975243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 7</th>\n",
       "      <td>0.892681</td>\n",
       "      <td>0.980612</td>\n",
       "      <td>0.980882</td>\n",
       "      <td>0.979530</td>\n",
       "      <td>0.980352</td>\n",
       "      <td>0.980078</td>\n",
       "      <td>0.979179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977881</td>\n",
       "      <td>0.979059</td>\n",
       "      <td>0.985093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 8</th>\n",
       "      <td>0.888974</td>\n",
       "      <td>0.971332</td>\n",
       "      <td>0.972258</td>\n",
       "      <td>0.971437</td>\n",
       "      <td>0.971513</td>\n",
       "      <td>0.971552</td>\n",
       "      <td>0.970682</td>\n",
       "      <td>0.977881</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995023</td>\n",
       "      <td>0.975779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 9</th>\n",
       "      <td>0.891214</td>\n",
       "      <td>0.973502</td>\n",
       "      <td>0.974200</td>\n",
       "      <td>0.973341</td>\n",
       "      <td>0.973611</td>\n",
       "      <td>0.974032</td>\n",
       "      <td>0.972447</td>\n",
       "      <td>0.979059</td>\n",
       "      <td>0.995023</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model 10</th>\n",
       "      <td>0.893118</td>\n",
       "      <td>0.978185</td>\n",
       "      <td>0.978884</td>\n",
       "      <td>0.977717</td>\n",
       "      <td>0.978701</td>\n",
       "      <td>0.977760</td>\n",
       "      <td>0.975243</td>\n",
       "      <td>0.985093</td>\n",
       "      <td>0.975779</td>\n",
       "      <td>0.978260</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 y   Model 1   Model 2   Model 3   Model 4   Model 5  \\\n",
       "y         1.000000  0.902615  0.902313  0.903493  0.902737  0.901657   \n",
       "Model 1   0.902615  1.000000  0.997024  0.996247  0.997808  0.996032   \n",
       "Model 2   0.902313  0.997024  1.000000  0.996003  0.996968  0.995125   \n",
       "Model 3   0.903493  0.996247  0.996003  1.000000  0.996353  0.994586   \n",
       "Model 4   0.902737  0.997808  0.996968  0.996353  1.000000  0.996068   \n",
       "Model 5   0.901657  0.996032  0.995125  0.994586  0.996068  1.000000   \n",
       "Model 6   0.903730  0.996784  0.996271  0.996167  0.996968  0.995711   \n",
       "Model 7   0.892681  0.980612  0.980882  0.979530  0.980352  0.980078   \n",
       "Model 8   0.888974  0.971332  0.972258  0.971437  0.971513  0.971552   \n",
       "Model 9   0.891214  0.973502  0.974200  0.973341  0.973611  0.974032   \n",
       "Model 10  0.893118  0.978185  0.978884  0.977717  0.978701  0.977760   \n",
       "\n",
       "           Model 6   Model 7   Model 8   Model 9  Model 10  \n",
       "y         0.903730  0.892681  0.888974  0.891214  0.893118  \n",
       "Model 1   0.996784  0.980612  0.971332  0.973502  0.978185  \n",
       "Model 2   0.996271  0.980882  0.972258  0.974200  0.978884  \n",
       "Model 3   0.996167  0.979530  0.971437  0.973341  0.977717  \n",
       "Model 4   0.996968  0.980352  0.971513  0.973611  0.978701  \n",
       "Model 5   0.995711  0.980078  0.971552  0.974032  0.977760  \n",
       "Model 6   1.000000  0.979179  0.970682  0.972447  0.975243  \n",
       "Model 7   0.979179  1.000000  0.977881  0.979059  0.985093  \n",
       "Model 8   0.970682  0.977881  1.000000  0.995023  0.975779  \n",
       "Model 9   0.972447  0.979059  0.995023  1.000000  0.978260  \n",
       "Model 10  0.975243  0.985093  0.975779  0.978260  1.000000  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maindf.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model 1 Diff</th>\n",
       "      <th>Model 2 Diff</th>\n",
       "      <th>Model 3 Diff</th>\n",
       "      <th>Model 4 Diff</th>\n",
       "      <th>Model 5 Diff</th>\n",
       "      <th>Model 6 Diff</th>\n",
       "      <th>Model 7 Diff</th>\n",
       "      <th>Model 8 Diff</th>\n",
       "      <th>Model 9 Diff</th>\n",
       "      <th>Model 10 Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-22478.121480</td>\n",
       "      <td>-29673.598503</td>\n",
       "      <td>-24867.199040</td>\n",
       "      <td>-22712.616299</td>\n",
       "      <td>-24780.031377</td>\n",
       "      <td>-21820.414108</td>\n",
       "      <td>-21878.326243</td>\n",
       "      <td>-26240.25000</td>\n",
       "      <td>-27124.90625</td>\n",
       "      <td>-3910.018038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22978.985356</td>\n",
       "      <td>5683.720081</td>\n",
       "      <td>12255.082089</td>\n",
       "      <td>15404.683470</td>\n",
       "      <td>12151.929533</td>\n",
       "      <td>-316.155637</td>\n",
       "      <td>30466.785533</td>\n",
       "      <td>9241.68750</td>\n",
       "      <td>26725.40625</td>\n",
       "      <td>43025.002584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14602.175458</td>\n",
       "      <td>5046.483351</td>\n",
       "      <td>11062.807700</td>\n",
       "      <td>-1364.948614</td>\n",
       "      <td>12908.086621</td>\n",
       "      <td>22633.683838</td>\n",
       "      <td>59588.582278</td>\n",
       "      <td>39659.00000</td>\n",
       "      <td>42264.93750</td>\n",
       "      <td>87381.119324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17498.554500</td>\n",
       "      <td>27621.162562</td>\n",
       "      <td>8388.046314</td>\n",
       "      <td>28337.601711</td>\n",
       "      <td>17937.897821</td>\n",
       "      <td>21730.052506</td>\n",
       "      <td>5323.702360</td>\n",
       "      <td>-1709.37500</td>\n",
       "      <td>20706.93750</td>\n",
       "      <td>53345.022702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-19067.969479</td>\n",
       "      <td>-35157.989533</td>\n",
       "      <td>-10936.380702</td>\n",
       "      <td>-13679.653122</td>\n",
       "      <td>-18509.761021</td>\n",
       "      <td>-16104.067663</td>\n",
       "      <td>-4559.203163</td>\n",
       "      <td>-12920.15625</td>\n",
       "      <td>-9848.34375</td>\n",
       "      <td>26184.629669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37752.681107</td>\n",
       "      <td>34312.615583</td>\n",
       "      <td>41245.691434</td>\n",
       "      <td>45523.589189</td>\n",
       "      <td>38453.651624</td>\n",
       "      <td>35881.107695</td>\n",
       "      <td>44287.818052</td>\n",
       "      <td>54651.15625</td>\n",
       "      <td>57718.31250</td>\n",
       "      <td>64094.880491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-67413.036767</td>\n",
       "      <td>-100109.612995</td>\n",
       "      <td>-90199.339287</td>\n",
       "      <td>-73978.867621</td>\n",
       "      <td>-78354.427703</td>\n",
       "      <td>-82132.609741</td>\n",
       "      <td>-30996.027158</td>\n",
       "      <td>-34466.56250</td>\n",
       "      <td>-12263.81250</td>\n",
       "      <td>-878.683414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>27330.304246</td>\n",
       "      <td>2078.594993</td>\n",
       "      <td>-26046.937815</td>\n",
       "      <td>-2735.823772</td>\n",
       "      <td>-6805.882736</td>\n",
       "      <td>-23535.771356</td>\n",
       "      <td>50785.757512</td>\n",
       "      <td>-22530.50000</td>\n",
       "      <td>-15579.53125</td>\n",
       "      <td>-37618.115915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-75329.348725</td>\n",
       "      <td>-66600.399720</td>\n",
       "      <td>-76000.766930</td>\n",
       "      <td>-67889.411091</td>\n",
       "      <td>-69884.481997</td>\n",
       "      <td>-74682.761053</td>\n",
       "      <td>-89016.686830</td>\n",
       "      <td>-107335.03125</td>\n",
       "      <td>-58981.28125</td>\n",
       "      <td>-31993.399388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-45307.290000</td>\n",
       "      <td>-41132.434193</td>\n",
       "      <td>-37321.575359</td>\n",
       "      <td>-44746.029002</td>\n",
       "      <td>-51128.041376</td>\n",
       "      <td>-57633.754744</td>\n",
       "      <td>-6106.760791</td>\n",
       "      <td>-7434.43750</td>\n",
       "      <td>-121.25000</td>\n",
       "      <td>34900.964584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model 1 Diff   Model 2 Diff  Model 3 Diff  Model 4 Diff  Model 5 Diff  \\\n",
       "0 -22478.121480  -29673.598503 -24867.199040 -22712.616299 -24780.031377   \n",
       "1  22978.985356    5683.720081  12255.082089  15404.683470  12151.929533   \n",
       "2  14602.175458    5046.483351  11062.807700  -1364.948614  12908.086621   \n",
       "3  17498.554500   27621.162562   8388.046314  28337.601711  17937.897821   \n",
       "4 -19067.969479  -35157.989533 -10936.380702 -13679.653122 -18509.761021   \n",
       "5  37752.681107   34312.615583  41245.691434  45523.589189  38453.651624   \n",
       "6 -67413.036767 -100109.612995 -90199.339287 -73978.867621 -78354.427703   \n",
       "7  27330.304246    2078.594993 -26046.937815  -2735.823772  -6805.882736   \n",
       "8 -75329.348725  -66600.399720 -76000.766930 -67889.411091 -69884.481997   \n",
       "9 -45307.290000  -41132.434193 -37321.575359 -44746.029002 -51128.041376   \n",
       "\n",
       "   Model 6 Diff  Model 7 Diff  Model 8 Diff  Model 9 Diff  Model 10 Diff  \n",
       "0 -21820.414108 -21878.326243  -26240.25000  -27124.90625   -3910.018038  \n",
       "1   -316.155637  30466.785533    9241.68750   26725.40625   43025.002584  \n",
       "2  22633.683838  59588.582278   39659.00000   42264.93750   87381.119324  \n",
       "3  21730.052506   5323.702360   -1709.37500   20706.93750   53345.022702  \n",
       "4 -16104.067663  -4559.203163  -12920.15625   -9848.34375   26184.629669  \n",
       "5  35881.107695  44287.818052   54651.15625   57718.31250   64094.880491  \n",
       "6 -82132.609741 -30996.027158  -34466.56250  -12263.81250    -878.683414  \n",
       "7 -23535.771356  50785.757512  -22530.50000  -15579.53125  -37618.115915  \n",
       "8 -74682.761053 -89016.686830 -107335.03125  -58981.28125  -31993.399388  \n",
       "9 -57633.754744  -6106.760791   -7434.43750    -121.25000   34900.964584  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secdf=pd.DataFrame()\n",
    "secdf[\"Model 1 Diff\"]=maindf[\"Model 1\"] - maindf['y']\n",
    "secdf[\"Model 2 Diff\"]=maindf[\"Model 2\"] - maindf['y']\n",
    "secdf[\"Model 3 Diff\"]=maindf[\"Model 3\"] - maindf['y']\n",
    "secdf[\"Model 4 Diff\"]=maindf[\"Model 4\"] - maindf['y']\n",
    "secdf[\"Model 5 Diff\"]=maindf[\"Model 5\"] - maindf['y']\n",
    "secdf[\"Model 6 Diff\"]=maindf[\"Model 6\"] - maindf['y']\n",
    "secdf[\"Model 7 Diff\"]=maindf[\"Model 7\"] - maindf['y']\n",
    "secdf[\"Model 8 Diff\"]=maindf[\"Model 8\"] - maindf['y']\n",
    "secdf[\"Model 9 Diff\"]=maindf[\"Model 9\"] - maindf['y']\n",
    "secdf[\"Model 10 Diff\"]=maindf[\"Model 10\"] - maindf['y']\n",
    "\n",
    "secdf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model 1 Diff</th>\n",
       "      <th>Model 2 Diff</th>\n",
       "      <th>Model 3 Diff</th>\n",
       "      <th>Model 4 Diff</th>\n",
       "      <th>Model 5 Diff</th>\n",
       "      <th>Model 6 Diff</th>\n",
       "      <th>Model 7 Diff</th>\n",
       "      <th>Model 8 Diff</th>\n",
       "      <th>Model 9 Diff</th>\n",
       "      <th>Model 10 Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.078871</td>\n",
       "      <td>0.104118</td>\n",
       "      <td>0.087253</td>\n",
       "      <td>0.079693</td>\n",
       "      <td>0.086947</td>\n",
       "      <td>0.076563</td>\n",
       "      <td>0.076766</td>\n",
       "      <td>0.092071</td>\n",
       "      <td>0.095175</td>\n",
       "      <td>0.013719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.074138</td>\n",
       "      <td>0.018338</td>\n",
       "      <td>0.039539</td>\n",
       "      <td>0.049701</td>\n",
       "      <td>0.039206</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.098296</td>\n",
       "      <td>0.029817</td>\n",
       "      <td>0.086225</td>\n",
       "      <td>0.138813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030677</td>\n",
       "      <td>0.010602</td>\n",
       "      <td>0.023241</td>\n",
       "      <td>0.002868</td>\n",
       "      <td>0.027118</td>\n",
       "      <td>0.047550</td>\n",
       "      <td>0.125186</td>\n",
       "      <td>0.083317</td>\n",
       "      <td>0.088792</td>\n",
       "      <td>0.183574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.053850</td>\n",
       "      <td>0.085001</td>\n",
       "      <td>0.025813</td>\n",
       "      <td>0.087206</td>\n",
       "      <td>0.055202</td>\n",
       "      <td>0.066872</td>\n",
       "      <td>0.016383</td>\n",
       "      <td>0.005260</td>\n",
       "      <td>0.063723</td>\n",
       "      <td>0.164164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.058671</td>\n",
       "      <td>0.108178</td>\n",
       "      <td>0.033650</td>\n",
       "      <td>0.042091</td>\n",
       "      <td>0.056953</td>\n",
       "      <td>0.049551</td>\n",
       "      <td>0.014028</td>\n",
       "      <td>0.039754</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.080568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.160650</td>\n",
       "      <td>0.146011</td>\n",
       "      <td>0.175514</td>\n",
       "      <td>0.193717</td>\n",
       "      <td>0.163633</td>\n",
       "      <td>0.152686</td>\n",
       "      <td>0.188459</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.245610</td>\n",
       "      <td>0.272744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.103189</td>\n",
       "      <td>0.153238</td>\n",
       "      <td>0.138068</td>\n",
       "      <td>0.113240</td>\n",
       "      <td>0.119937</td>\n",
       "      <td>0.125721</td>\n",
       "      <td>0.047446</td>\n",
       "      <td>0.052758</td>\n",
       "      <td>0.018772</td>\n",
       "      <td>0.001345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.073866</td>\n",
       "      <td>0.005618</td>\n",
       "      <td>0.070397</td>\n",
       "      <td>0.007394</td>\n",
       "      <td>0.018394</td>\n",
       "      <td>0.063610</td>\n",
       "      <td>0.137259</td>\n",
       "      <td>0.060893</td>\n",
       "      <td>0.042107</td>\n",
       "      <td>0.101671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.224897</td>\n",
       "      <td>0.198837</td>\n",
       "      <td>0.226902</td>\n",
       "      <td>0.202685</td>\n",
       "      <td>0.208642</td>\n",
       "      <td>0.222967</td>\n",
       "      <td>0.265761</td>\n",
       "      <td>0.320451</td>\n",
       "      <td>0.176090</td>\n",
       "      <td>0.095517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.072492</td>\n",
       "      <td>0.065812</td>\n",
       "      <td>0.059715</td>\n",
       "      <td>0.071594</td>\n",
       "      <td>0.081805</td>\n",
       "      <td>0.092214</td>\n",
       "      <td>0.009771</td>\n",
       "      <td>0.011895</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.055842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.467413</td>\n",
       "      <td>0.436411</td>\n",
       "      <td>0.629935</td>\n",
       "      <td>0.506558</td>\n",
       "      <td>0.466491</td>\n",
       "      <td>0.432700</td>\n",
       "      <td>0.441693</td>\n",
       "      <td>0.377692</td>\n",
       "      <td>0.474386</td>\n",
       "      <td>0.511409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.086842</td>\n",
       "      <td>0.163222</td>\n",
       "      <td>0.158354</td>\n",
       "      <td>0.116525</td>\n",
       "      <td>0.086594</td>\n",
       "      <td>0.116128</td>\n",
       "      <td>0.191042</td>\n",
       "      <td>0.159216</td>\n",
       "      <td>0.109981</td>\n",
       "      <td>0.107808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.135782</td>\n",
       "      <td>0.169085</td>\n",
       "      <td>0.174149</td>\n",
       "      <td>0.148088</td>\n",
       "      <td>0.171622</td>\n",
       "      <td>0.167462</td>\n",
       "      <td>0.199008</td>\n",
       "      <td>0.170266</td>\n",
       "      <td>0.164032</td>\n",
       "      <td>0.109853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.133903</td>\n",
       "      <td>0.128002</td>\n",
       "      <td>0.157349</td>\n",
       "      <td>0.193687</td>\n",
       "      <td>0.129405</td>\n",
       "      <td>0.153104</td>\n",
       "      <td>0.157808</td>\n",
       "      <td>0.146544</td>\n",
       "      <td>0.131347</td>\n",
       "      <td>0.260801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.141795</td>\n",
       "      <td>0.154158</td>\n",
       "      <td>0.147497</td>\n",
       "      <td>0.146396</td>\n",
       "      <td>0.162849</td>\n",
       "      <td>0.160292</td>\n",
       "      <td>0.172950</td>\n",
       "      <td>0.168071</td>\n",
       "      <td>0.160524</td>\n",
       "      <td>0.134126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.176096</td>\n",
       "      <td>0.198613</td>\n",
       "      <td>0.175780</td>\n",
       "      <td>0.159921</td>\n",
       "      <td>0.175879</td>\n",
       "      <td>0.189513</td>\n",
       "      <td>0.220710</td>\n",
       "      <td>0.198615</td>\n",
       "      <td>0.180883</td>\n",
       "      <td>0.170419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.161808</td>\n",
       "      <td>0.153522</td>\n",
       "      <td>0.166062</td>\n",
       "      <td>0.149967</td>\n",
       "      <td>0.165562</td>\n",
       "      <td>0.164578</td>\n",
       "      <td>0.170143</td>\n",
       "      <td>0.151602</td>\n",
       "      <td>0.161541</td>\n",
       "      <td>0.148839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.072305</td>\n",
       "      <td>0.026041</td>\n",
       "      <td>0.091676</td>\n",
       "      <td>0.113058</td>\n",
       "      <td>0.070921</td>\n",
       "      <td>0.101601</td>\n",
       "      <td>0.139730</td>\n",
       "      <td>0.114069</td>\n",
       "      <td>0.124125</td>\n",
       "      <td>0.011182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.022552</td>\n",
       "      <td>0.080409</td>\n",
       "      <td>0.010190</td>\n",
       "      <td>0.021409</td>\n",
       "      <td>0.048198</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>0.010256</td>\n",
       "      <td>0.017431</td>\n",
       "      <td>0.048357</td>\n",
       "      <td>0.070034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.080480</td>\n",
       "      <td>0.073148</td>\n",
       "      <td>0.075363</td>\n",
       "      <td>0.076634</td>\n",
       "      <td>0.026162</td>\n",
       "      <td>0.098767</td>\n",
       "      <td>0.162256</td>\n",
       "      <td>0.259642</td>\n",
       "      <td>0.211195</td>\n",
       "      <td>0.159922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.037312</td>\n",
       "      <td>0.009393</td>\n",
       "      <td>0.023931</td>\n",
       "      <td>0.019798</td>\n",
       "      <td>0.034529</td>\n",
       "      <td>0.030673</td>\n",
       "      <td>0.068162</td>\n",
       "      <td>0.171370</td>\n",
       "      <td>0.135341</td>\n",
       "      <td>0.078556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.043270</td>\n",
       "      <td>0.018026</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>0.026881</td>\n",
       "      <td>0.028470</td>\n",
       "      <td>0.005475</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>0.005352</td>\n",
       "      <td>0.018146</td>\n",
       "      <td>0.055604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.192799</td>\n",
       "      <td>0.186845</td>\n",
       "      <td>0.175822</td>\n",
       "      <td>0.217052</td>\n",
       "      <td>0.236523</td>\n",
       "      <td>0.144352</td>\n",
       "      <td>0.167628</td>\n",
       "      <td>0.105156</td>\n",
       "      <td>0.108954</td>\n",
       "      <td>0.213621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.029739</td>\n",
       "      <td>0.065654</td>\n",
       "      <td>0.028438</td>\n",
       "      <td>0.027464</td>\n",
       "      <td>0.036667</td>\n",
       "      <td>0.030788</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>0.006318</td>\n",
       "      <td>0.032944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.080560</td>\n",
       "      <td>0.083107</td>\n",
       "      <td>0.136396</td>\n",
       "      <td>0.103589</td>\n",
       "      <td>0.091104</td>\n",
       "      <td>0.082480</td>\n",
       "      <td>0.183582</td>\n",
       "      <td>0.115790</td>\n",
       "      <td>0.094451</td>\n",
       "      <td>0.092004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.163069</td>\n",
       "      <td>0.187296</td>\n",
       "      <td>0.097499</td>\n",
       "      <td>0.138703</td>\n",
       "      <td>0.167956</td>\n",
       "      <td>0.131191</td>\n",
       "      <td>0.095920</td>\n",
       "      <td>0.097167</td>\n",
       "      <td>0.100492</td>\n",
       "      <td>0.102138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.082111</td>\n",
       "      <td>0.124546</td>\n",
       "      <td>0.051522</td>\n",
       "      <td>0.102011</td>\n",
       "      <td>0.065702</td>\n",
       "      <td>0.076150</td>\n",
       "      <td>0.084558</td>\n",
       "      <td>0.141102</td>\n",
       "      <td>0.168928</td>\n",
       "      <td>0.279080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.187455</td>\n",
       "      <td>0.205549</td>\n",
       "      <td>0.179397</td>\n",
       "      <td>0.168530</td>\n",
       "      <td>0.139529</td>\n",
       "      <td>0.159662</td>\n",
       "      <td>0.161532</td>\n",
       "      <td>0.206122</td>\n",
       "      <td>0.279421</td>\n",
       "      <td>0.373550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.184632</td>\n",
       "      <td>0.183979</td>\n",
       "      <td>0.173674</td>\n",
       "      <td>0.148241</td>\n",
       "      <td>0.208461</td>\n",
       "      <td>0.206761</td>\n",
       "      <td>0.276958</td>\n",
       "      <td>0.160201</td>\n",
       "      <td>0.172787</td>\n",
       "      <td>0.151212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.167862</td>\n",
       "      <td>0.199335</td>\n",
       "      <td>0.164689</td>\n",
       "      <td>0.173893</td>\n",
       "      <td>0.207526</td>\n",
       "      <td>0.213794</td>\n",
       "      <td>0.186409</td>\n",
       "      <td>0.120689</td>\n",
       "      <td>0.096174</td>\n",
       "      <td>0.008133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11555</th>\n",
       "      <td>0.032598</td>\n",
       "      <td>0.042873</td>\n",
       "      <td>0.028022</td>\n",
       "      <td>0.034337</td>\n",
       "      <td>0.026326</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>0.007776</td>\n",
       "      <td>0.009980</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.070618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11556</th>\n",
       "      <td>0.054536</td>\n",
       "      <td>0.091803</td>\n",
       "      <td>0.046302</td>\n",
       "      <td>0.066981</td>\n",
       "      <td>0.061643</td>\n",
       "      <td>0.071931</td>\n",
       "      <td>0.139359</td>\n",
       "      <td>0.165758</td>\n",
       "      <td>0.123198</td>\n",
       "      <td>0.034487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11557</th>\n",
       "      <td>0.229351</td>\n",
       "      <td>0.231240</td>\n",
       "      <td>0.279564</td>\n",
       "      <td>0.241774</td>\n",
       "      <td>0.175643</td>\n",
       "      <td>0.247124</td>\n",
       "      <td>0.246292</td>\n",
       "      <td>0.226932</td>\n",
       "      <td>0.268598</td>\n",
       "      <td>0.240622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11558</th>\n",
       "      <td>0.197318</td>\n",
       "      <td>0.197727</td>\n",
       "      <td>0.179193</td>\n",
       "      <td>0.176282</td>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.164335</td>\n",
       "      <td>0.212682</td>\n",
       "      <td>0.200378</td>\n",
       "      <td>0.217024</td>\n",
       "      <td>0.232822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11559</th>\n",
       "      <td>0.054450</td>\n",
       "      <td>0.084792</td>\n",
       "      <td>0.014407</td>\n",
       "      <td>0.059275</td>\n",
       "      <td>0.055329</td>\n",
       "      <td>0.064332</td>\n",
       "      <td>0.106646</td>\n",
       "      <td>0.125494</td>\n",
       "      <td>0.125680</td>\n",
       "      <td>0.022734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11560</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.001590</td>\n",
       "      <td>0.051522</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.061267</td>\n",
       "      <td>0.023035</td>\n",
       "      <td>0.017256</td>\n",
       "      <td>0.082584</td>\n",
       "      <td>0.030359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11561</th>\n",
       "      <td>0.053284</td>\n",
       "      <td>0.058966</td>\n",
       "      <td>0.049806</td>\n",
       "      <td>0.053958</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.079367</td>\n",
       "      <td>0.049820</td>\n",
       "      <td>0.007149</td>\n",
       "      <td>0.089358</td>\n",
       "      <td>0.000848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11562</th>\n",
       "      <td>0.196745</td>\n",
       "      <td>0.243819</td>\n",
       "      <td>0.266760</td>\n",
       "      <td>0.301750</td>\n",
       "      <td>0.235141</td>\n",
       "      <td>0.234768</td>\n",
       "      <td>0.353132</td>\n",
       "      <td>0.282742</td>\n",
       "      <td>0.406712</td>\n",
       "      <td>0.430883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11563</th>\n",
       "      <td>0.021101</td>\n",
       "      <td>0.033132</td>\n",
       "      <td>0.011821</td>\n",
       "      <td>0.024042</td>\n",
       "      <td>0.053783</td>\n",
       "      <td>0.052674</td>\n",
       "      <td>0.032537</td>\n",
       "      <td>0.075579</td>\n",
       "      <td>0.074946</td>\n",
       "      <td>0.063273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11564</th>\n",
       "      <td>0.084927</td>\n",
       "      <td>0.024308</td>\n",
       "      <td>0.007417</td>\n",
       "      <td>0.073416</td>\n",
       "      <td>0.089966</td>\n",
       "      <td>0.054519</td>\n",
       "      <td>0.159552</td>\n",
       "      <td>0.124799</td>\n",
       "      <td>0.198545</td>\n",
       "      <td>0.246197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11565</th>\n",
       "      <td>0.010340</td>\n",
       "      <td>0.033301</td>\n",
       "      <td>0.009982</td>\n",
       "      <td>0.013934</td>\n",
       "      <td>0.044218</td>\n",
       "      <td>0.010445</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.027223</td>\n",
       "      <td>0.016801</td>\n",
       "      <td>0.017131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11566</th>\n",
       "      <td>0.083034</td>\n",
       "      <td>0.053317</td>\n",
       "      <td>0.039816</td>\n",
       "      <td>0.063258</td>\n",
       "      <td>0.078067</td>\n",
       "      <td>0.013764</td>\n",
       "      <td>0.014021</td>\n",
       "      <td>0.043261</td>\n",
       "      <td>0.007546</td>\n",
       "      <td>0.112520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11567</th>\n",
       "      <td>0.130750</td>\n",
       "      <td>0.194496</td>\n",
       "      <td>0.201228</td>\n",
       "      <td>0.234055</td>\n",
       "      <td>0.197036</td>\n",
       "      <td>0.154022</td>\n",
       "      <td>0.306333</td>\n",
       "      <td>0.282364</td>\n",
       "      <td>0.386768</td>\n",
       "      <td>0.413357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11568</th>\n",
       "      <td>0.085891</td>\n",
       "      <td>0.066926</td>\n",
       "      <td>0.027954</td>\n",
       "      <td>0.055309</td>\n",
       "      <td>0.082999</td>\n",
       "      <td>0.017713</td>\n",
       "      <td>0.052131</td>\n",
       "      <td>0.037762</td>\n",
       "      <td>0.090842</td>\n",
       "      <td>0.149058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11569</th>\n",
       "      <td>0.012190</td>\n",
       "      <td>0.009095</td>\n",
       "      <td>0.053126</td>\n",
       "      <td>0.054145</td>\n",
       "      <td>0.042928</td>\n",
       "      <td>0.063701</td>\n",
       "      <td>0.029235</td>\n",
       "      <td>0.067583</td>\n",
       "      <td>0.060698</td>\n",
       "      <td>0.026035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11570</th>\n",
       "      <td>0.048906</td>\n",
       "      <td>0.052221</td>\n",
       "      <td>0.040307</td>\n",
       "      <td>0.019073</td>\n",
       "      <td>0.061220</td>\n",
       "      <td>0.010904</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.018610</td>\n",
       "      <td>0.066914</td>\n",
       "      <td>0.086066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11571</th>\n",
       "      <td>0.077605</td>\n",
       "      <td>0.097938</td>\n",
       "      <td>0.182523</td>\n",
       "      <td>0.181111</td>\n",
       "      <td>0.080716</td>\n",
       "      <td>0.204459</td>\n",
       "      <td>0.100707</td>\n",
       "      <td>0.027908</td>\n",
       "      <td>0.034283</td>\n",
       "      <td>0.167055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11572</th>\n",
       "      <td>0.002925</td>\n",
       "      <td>0.089005</td>\n",
       "      <td>0.043906</td>\n",
       "      <td>0.118386</td>\n",
       "      <td>0.076351</td>\n",
       "      <td>0.023608</td>\n",
       "      <td>0.248792</td>\n",
       "      <td>0.210463</td>\n",
       "      <td>0.253889</td>\n",
       "      <td>0.257151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11573</th>\n",
       "      <td>0.031220</td>\n",
       "      <td>0.032352</td>\n",
       "      <td>0.054249</td>\n",
       "      <td>0.015493</td>\n",
       "      <td>0.056312</td>\n",
       "      <td>0.004672</td>\n",
       "      <td>0.043228</td>\n",
       "      <td>0.017175</td>\n",
       "      <td>0.024936</td>\n",
       "      <td>0.079908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11574</th>\n",
       "      <td>0.081197</td>\n",
       "      <td>0.107406</td>\n",
       "      <td>0.083522</td>\n",
       "      <td>0.119839</td>\n",
       "      <td>0.082898</td>\n",
       "      <td>0.030017</td>\n",
       "      <td>0.074110</td>\n",
       "      <td>0.023012</td>\n",
       "      <td>0.069749</td>\n",
       "      <td>0.043348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11575</th>\n",
       "      <td>0.008503</td>\n",
       "      <td>0.012574</td>\n",
       "      <td>0.017621</td>\n",
       "      <td>0.038012</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.070657</td>\n",
       "      <td>0.035192</td>\n",
       "      <td>0.023824</td>\n",
       "      <td>0.002656</td>\n",
       "      <td>0.022007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11576</th>\n",
       "      <td>0.447323</td>\n",
       "      <td>0.409521</td>\n",
       "      <td>0.419927</td>\n",
       "      <td>0.491211</td>\n",
       "      <td>0.460539</td>\n",
       "      <td>0.490589</td>\n",
       "      <td>0.521941</td>\n",
       "      <td>0.600346</td>\n",
       "      <td>0.583187</td>\n",
       "      <td>0.588796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11577</th>\n",
       "      <td>0.053437</td>\n",
       "      <td>0.007514</td>\n",
       "      <td>0.041178</td>\n",
       "      <td>0.135558</td>\n",
       "      <td>0.082933</td>\n",
       "      <td>0.075009</td>\n",
       "      <td>0.043677</td>\n",
       "      <td>0.077142</td>\n",
       "      <td>0.011196</td>\n",
       "      <td>0.040489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11578</th>\n",
       "      <td>0.169393</td>\n",
       "      <td>0.143020</td>\n",
       "      <td>0.132938</td>\n",
       "      <td>0.152831</td>\n",
       "      <td>0.163795</td>\n",
       "      <td>0.114908</td>\n",
       "      <td>0.116386</td>\n",
       "      <td>0.109477</td>\n",
       "      <td>0.132012</td>\n",
       "      <td>0.201574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11579</th>\n",
       "      <td>0.007889</td>\n",
       "      <td>0.042345</td>\n",
       "      <td>0.027511</td>\n",
       "      <td>0.078723</td>\n",
       "      <td>0.028204</td>\n",
       "      <td>0.084282</td>\n",
       "      <td>0.049953</td>\n",
       "      <td>0.066481</td>\n",
       "      <td>0.052298</td>\n",
       "      <td>0.030953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11580</th>\n",
       "      <td>0.125190</td>\n",
       "      <td>0.147242</td>\n",
       "      <td>0.151509</td>\n",
       "      <td>0.095313</td>\n",
       "      <td>0.114479</td>\n",
       "      <td>0.133224</td>\n",
       "      <td>0.114095</td>\n",
       "      <td>0.177157</td>\n",
       "      <td>0.172396</td>\n",
       "      <td>0.105809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11581</th>\n",
       "      <td>0.170589</td>\n",
       "      <td>0.166605</td>\n",
       "      <td>0.139558</td>\n",
       "      <td>0.169463</td>\n",
       "      <td>0.179431</td>\n",
       "      <td>0.128431</td>\n",
       "      <td>0.130289</td>\n",
       "      <td>0.154987</td>\n",
       "      <td>0.166835</td>\n",
       "      <td>0.137018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11582</th>\n",
       "      <td>0.094912</td>\n",
       "      <td>0.099057</td>\n",
       "      <td>0.061265</td>\n",
       "      <td>0.065223</td>\n",
       "      <td>0.109992</td>\n",
       "      <td>0.092756</td>\n",
       "      <td>0.074395</td>\n",
       "      <td>0.076135</td>\n",
       "      <td>0.080568</td>\n",
       "      <td>0.028663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11583</th>\n",
       "      <td>0.050780</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.060079</td>\n",
       "      <td>0.062827</td>\n",
       "      <td>0.006395</td>\n",
       "      <td>0.068281</td>\n",
       "      <td>0.255912</td>\n",
       "      <td>0.139592</td>\n",
       "      <td>0.167721</td>\n",
       "      <td>0.293952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11584</th>\n",
       "      <td>0.098242</td>\n",
       "      <td>0.104462</td>\n",
       "      <td>0.079406</td>\n",
       "      <td>0.091648</td>\n",
       "      <td>0.108921</td>\n",
       "      <td>0.051450</td>\n",
       "      <td>0.075736</td>\n",
       "      <td>0.093892</td>\n",
       "      <td>0.106684</td>\n",
       "      <td>0.100256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11585 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model 1 Diff  Model 2 Diff  Model 3 Diff  Model 4 Diff  Model 5 Diff  \\\n",
       "0          0.078871      0.104118      0.087253      0.079693      0.086947   \n",
       "1          0.074138      0.018338      0.039539      0.049701      0.039206   \n",
       "2          0.030677      0.010602      0.023241      0.002868      0.027118   \n",
       "3          0.053850      0.085001      0.025813      0.087206      0.055202   \n",
       "4          0.058671      0.108178      0.033650      0.042091      0.056953   \n",
       "5          0.160650      0.146011      0.175514      0.193717      0.163633   \n",
       "6          0.103189      0.153238      0.138068      0.113240      0.119937   \n",
       "7          0.073866      0.005618      0.070397      0.007394      0.018394   \n",
       "8          0.224897      0.198837      0.226902      0.202685      0.208642   \n",
       "9          0.072492      0.065812      0.059715      0.071594      0.081805   \n",
       "10         0.467413      0.436411      0.629935      0.506558      0.466491   \n",
       "11         0.086842      0.163222      0.158354      0.116525      0.086594   \n",
       "12         0.135782      0.169085      0.174149      0.148088      0.171622   \n",
       "13         0.133903      0.128002      0.157349      0.193687      0.129405   \n",
       "14         0.141795      0.154158      0.147497      0.146396      0.162849   \n",
       "15         0.176096      0.198613      0.175780      0.159921      0.175879   \n",
       "16         0.161808      0.153522      0.166062      0.149967      0.165562   \n",
       "17         0.072305      0.026041      0.091676      0.113058      0.070921   \n",
       "18         0.022552      0.080409      0.010190      0.021409      0.048198   \n",
       "19         0.080480      0.073148      0.075363      0.076634      0.026162   \n",
       "20         0.037312      0.009393      0.023931      0.019798      0.034529   \n",
       "21         0.043270      0.018026      0.001450      0.026881      0.028470   \n",
       "22         0.192799      0.186845      0.175822      0.217052      0.236523   \n",
       "23         0.029739      0.065654      0.028438      0.027464      0.036667   \n",
       "24         0.080560      0.083107      0.136396      0.103589      0.091104   \n",
       "25         0.163069      0.187296      0.097499      0.138703      0.167956   \n",
       "26         0.082111      0.124546      0.051522      0.102011      0.065702   \n",
       "27         0.187455      0.205549      0.179397      0.168530      0.139529   \n",
       "28         0.184632      0.183979      0.173674      0.148241      0.208461   \n",
       "29         0.167862      0.199335      0.164689      0.173893      0.207526   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "11555      0.032598      0.042873      0.028022      0.034337      0.026326   \n",
       "11556      0.054536      0.091803      0.046302      0.066981      0.061643   \n",
       "11557      0.229351      0.231240      0.279564      0.241774      0.175643   \n",
       "11558      0.197318      0.197727      0.179193      0.176282      0.229167   \n",
       "11559      0.054450      0.084792      0.014407      0.059275      0.055329   \n",
       "11560      0.005383      0.001590      0.051522      0.047782      0.003868   \n",
       "11561      0.053284      0.058966      0.049806      0.053958      0.001405   \n",
       "11562      0.196745      0.243819      0.266760      0.301750      0.235141   \n",
       "11563      0.021101      0.033132      0.011821      0.024042      0.053783   \n",
       "11564      0.084927      0.024308      0.007417      0.073416      0.089966   \n",
       "11565      0.010340      0.033301      0.009982      0.013934      0.044218   \n",
       "11566      0.083034      0.053317      0.039816      0.063258      0.078067   \n",
       "11567      0.130750      0.194496      0.201228      0.234055      0.197036   \n",
       "11568      0.085891      0.066926      0.027954      0.055309      0.082999   \n",
       "11569      0.012190      0.009095      0.053126      0.054145      0.042928   \n",
       "11570      0.048906      0.052221      0.040307      0.019073      0.061220   \n",
       "11571      0.077605      0.097938      0.182523      0.181111      0.080716   \n",
       "11572      0.002925      0.089005      0.043906      0.118386      0.076351   \n",
       "11573      0.031220      0.032352      0.054249      0.015493      0.056312   \n",
       "11574      0.081197      0.107406      0.083522      0.119839      0.082898   \n",
       "11575      0.008503      0.012574      0.017621      0.038012      0.004555   \n",
       "11576      0.447323      0.409521      0.419927      0.491211      0.460539   \n",
       "11577      0.053437      0.007514      0.041178      0.135558      0.082933   \n",
       "11578      0.169393      0.143020      0.132938      0.152831      0.163795   \n",
       "11579      0.007889      0.042345      0.027511      0.078723      0.028204   \n",
       "11580      0.125190      0.147242      0.151509      0.095313      0.114479   \n",
       "11581      0.170589      0.166605      0.139558      0.169463      0.179431   \n",
       "11582      0.094912      0.099057      0.061265      0.065223      0.109992   \n",
       "11583      0.050780      0.000359      0.060079      0.062827      0.006395   \n",
       "11584      0.098242      0.104462      0.079406      0.091648      0.108921   \n",
       "\n",
       "       Model 6 Diff  Model 7 Diff  Model 8 Diff  Model 9 Diff  Model 10 Diff  \n",
       "0          0.076563      0.076766      0.092071      0.095175       0.013719  \n",
       "1          0.001020      0.098296      0.029817      0.086225       0.138813  \n",
       "2          0.047550      0.125186      0.083317      0.088792       0.183574  \n",
       "3          0.066872      0.016383      0.005260      0.063723       0.164164  \n",
       "4          0.049551      0.014028      0.039754      0.030303       0.080568  \n",
       "5          0.152686      0.188459      0.232558      0.245610       0.272744  \n",
       "6          0.125721      0.047446      0.052758      0.018772       0.001345  \n",
       "7          0.063610      0.137259      0.060893      0.042107       0.101671  \n",
       "8          0.222967      0.265761      0.320451      0.176090       0.095517  \n",
       "9          0.092214      0.009771      0.011895      0.000194       0.055842  \n",
       "10         0.432700      0.441693      0.377692      0.474386       0.511409  \n",
       "11         0.116128      0.191042      0.159216      0.109981       0.107808  \n",
       "12         0.167462      0.199008      0.170266      0.164032       0.109853  \n",
       "13         0.153104      0.157808      0.146544      0.131347       0.260801  \n",
       "14         0.160292      0.172950      0.168071      0.160524       0.134126  \n",
       "15         0.189513      0.220710      0.198615      0.180883       0.170419  \n",
       "16         0.164578      0.170143      0.151602      0.161541       0.148839  \n",
       "17         0.101601      0.139730      0.114069      0.124125       0.011182  \n",
       "18         0.001224      0.010256      0.017431      0.048357       0.070034  \n",
       "19         0.098767      0.162256      0.259642      0.211195       0.159922  \n",
       "20         0.030673      0.068162      0.171370      0.135341       0.078556  \n",
       "21         0.005475      0.002806      0.005352      0.018146       0.055604  \n",
       "22         0.144352      0.167628      0.105156      0.108954       0.213621  \n",
       "23         0.030788      0.000311      0.004785      0.006318       0.032944  \n",
       "24         0.082480      0.183582      0.115790      0.094451       0.092004  \n",
       "25         0.131191      0.095920      0.097167      0.100492       0.102138  \n",
       "26         0.076150      0.084558      0.141102      0.168928       0.279080  \n",
       "27         0.159662      0.161532      0.206122      0.279421       0.373550  \n",
       "28         0.206761      0.276958      0.160201      0.172787       0.151212  \n",
       "29         0.213794      0.186409      0.120689      0.096174       0.008133  \n",
       "...             ...           ...           ...           ...            ...  \n",
       "11555      0.002533      0.007776      0.009980      0.001077       0.070618  \n",
       "11556      0.071931      0.139359      0.165758      0.123198       0.034487  \n",
       "11557      0.247124      0.246292      0.226932      0.268598       0.240622  \n",
       "11558      0.164335      0.212682      0.200378      0.217024       0.232822  \n",
       "11559      0.064332      0.106646      0.125494      0.125680       0.022734  \n",
       "11560      0.061267      0.023035      0.017256      0.082584       0.030359  \n",
       "11561      0.079367      0.049820      0.007149      0.089358       0.000848  \n",
       "11562      0.234768      0.353132      0.282742      0.406712       0.430883  \n",
       "11563      0.052674      0.032537      0.075579      0.074946       0.063273  \n",
       "11564      0.054519      0.159552      0.124799      0.198545       0.246197  \n",
       "11565      0.010445      0.000765      0.027223      0.016801       0.017131  \n",
       "11566      0.013764      0.014021      0.043261      0.007546       0.112520  \n",
       "11567      0.154022      0.306333      0.282364      0.386768       0.413357  \n",
       "11568      0.017713      0.052131      0.037762      0.090842       0.149058  \n",
       "11569      0.063701      0.029235      0.067583      0.060698       0.026035  \n",
       "11570      0.010904      0.011400      0.018610      0.066914       0.086066  \n",
       "11571      0.204459      0.100707      0.027908      0.034283       0.167055  \n",
       "11572      0.023608      0.248792      0.210463      0.253889       0.257151  \n",
       "11573      0.004672      0.043228      0.017175      0.024936       0.079908  \n",
       "11574      0.030017      0.074110      0.023012      0.069749       0.043348  \n",
       "11575      0.070657      0.035192      0.023824      0.002656       0.022007  \n",
       "11576      0.490589      0.521941      0.600346      0.583187       0.588796  \n",
       "11577      0.075009      0.043677      0.077142      0.011196       0.040489  \n",
       "11578      0.114908      0.116386      0.109477      0.132012       0.201574  \n",
       "11579      0.084282      0.049953      0.066481      0.052298       0.030953  \n",
       "11580      0.133224      0.114095      0.177157      0.172396       0.105809  \n",
       "11581      0.128431      0.130289      0.154987      0.166835       0.137018  \n",
       "11582      0.092756      0.074395      0.076135      0.080568       0.028663  \n",
       "11583      0.068281      0.255912      0.139592      0.167721       0.293952  \n",
       "11584      0.051450      0.075736      0.093892      0.106684       0.100256  \n",
       "\n",
       "[11585 rows x 10 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec=pd.DataFrame()\n",
    "sec[\"Model 1 Diff\"]=np.abs(maindf[\"Model 1\"] - maindf['y'])/maindf['y']\n",
    "sec[\"Model 2 Diff\"]=np.abs(maindf[\"Model 2\"] - maindf['y'])/maindf['y']\n",
    "sec[\"Model 3 Diff\"]=np.abs(maindf[\"Model 3\"] - maindf['y'])/maindf['y']\n",
    "sec[\"Model 4 Diff\"]=np.abs(maindf[\"Model 4\"] - maindf['y'])/maindf['y']\n",
    "sec[\"Model 5 Diff\"]=np.abs(maindf[\"Model 5\"] - maindf['y'])/maindf['y']\n",
    "sec[\"Model 6 Diff\"]=np.abs(maindf[\"Model 6\"] - maindf['y'])/maindf['y']\n",
    "sec[\"Model 7 Diff\"]=np.abs(maindf[\"Model 7\"] - maindf['y'])/maindf['y']\n",
    "sec[\"Model 8 Diff\"]=np.abs(maindf[\"Model 8\"] - maindf['y'])/maindf['y']\n",
    "sec[\"Model 9 Diff\"]=np.abs(maindf[\"Model 9\"] - maindf['y'])/maindf['y']\n",
    "sec[\"Model 10 Diff\"]=np.abs(maindf[\"Model 10\"] - maindf['y'])/maindf['y']\n",
    "\n",
    "sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model 1 Diff</th>\n",
       "      <th>Model 2 Diff</th>\n",
       "      <th>Model 3 Diff</th>\n",
       "      <th>Model 4 Diff</th>\n",
       "      <th>Model 5 Diff</th>\n",
       "      <th>Model 6 Diff</th>\n",
       "      <th>Model 7 Diff</th>\n",
       "      <th>Model 8 Diff</th>\n",
       "      <th>Model 9 Diff</th>\n",
       "      <th>Model 10 Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.158500e+04</td>\n",
       "      <td>1.158500e+04</td>\n",
       "      <td>1.158500e+04</td>\n",
       "      <td>1.158500e+04</td>\n",
       "      <td>1.158500e+04</td>\n",
       "      <td>1.158500e+04</td>\n",
       "      <td>1.158500e+04</td>\n",
       "      <td>1.158500e+04</td>\n",
       "      <td>1.158500e+04</td>\n",
       "      <td>1.158500e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.071248e+04</td>\n",
       "      <td>-1.651190e+04</td>\n",
       "      <td>-1.003327e+04</td>\n",
       "      <td>-9.459277e+03</td>\n",
       "      <td>-1.264379e+04</td>\n",
       "      <td>-1.145299e+04</td>\n",
       "      <td>-3.188869e+03</td>\n",
       "      <td>-5.163294e+03</td>\n",
       "      <td>-5.586760e+03</td>\n",
       "      <td>5.904763e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.970692e+05</td>\n",
       "      <td>1.974009e+05</td>\n",
       "      <td>1.962238e+05</td>\n",
       "      <td>1.969501e+05</td>\n",
       "      <td>1.979846e+05</td>\n",
       "      <td>1.959908e+05</td>\n",
       "      <td>2.066466e+05</td>\n",
       "      <td>2.099215e+05</td>\n",
       "      <td>2.077299e+05</td>\n",
       "      <td>2.059482e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.896860e+06</td>\n",
       "      <td>-4.081291e+06</td>\n",
       "      <td>-3.866715e+06</td>\n",
       "      <td>-3.827125e+06</td>\n",
       "      <td>-3.925216e+06</td>\n",
       "      <td>-4.015964e+06</td>\n",
       "      <td>-4.971180e+06</td>\n",
       "      <td>-4.790067e+06</td>\n",
       "      <td>-4.790068e+06</td>\n",
       "      <td>-4.500315e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.723497e+04</td>\n",
       "      <td>-5.164920e+04</td>\n",
       "      <td>-4.681198e+04</td>\n",
       "      <td>-4.630585e+04</td>\n",
       "      <td>-4.829316e+04</td>\n",
       "      <td>-4.767781e+04</td>\n",
       "      <td>-4.083493e+04</td>\n",
       "      <td>-4.173834e+04</td>\n",
       "      <td>-4.082184e+04</td>\n",
       "      <td>-3.374074e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-2.554371e+03</td>\n",
       "      <td>-6.355793e+03</td>\n",
       "      <td>-2.939206e+03</td>\n",
       "      <td>-1.364099e+03</td>\n",
       "      <td>-3.452520e+03</td>\n",
       "      <td>-3.034910e+03</td>\n",
       "      <td>1.904575e+03</td>\n",
       "      <td>2.072094e+03</td>\n",
       "      <td>2.730344e+03</td>\n",
       "      <td>9.930012e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.084156e+04</td>\n",
       "      <td>3.663483e+04</td>\n",
       "      <td>4.189445e+04</td>\n",
       "      <td>4.201571e+04</td>\n",
       "      <td>3.891881e+04</td>\n",
       "      <td>4.004456e+04</td>\n",
       "      <td>4.879335e+04</td>\n",
       "      <td>4.881912e+04</td>\n",
       "      <td>4.929825e+04</td>\n",
       "      <td>6.325047e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.665931e+06</td>\n",
       "      <td>2.558717e+06</td>\n",
       "      <td>2.613563e+06</td>\n",
       "      <td>2.739440e+06</td>\n",
       "      <td>2.599624e+06</td>\n",
       "      <td>2.709411e+06</td>\n",
       "      <td>2.693534e+06</td>\n",
       "      <td>3.015724e+06</td>\n",
       "      <td>3.182957e+06</td>\n",
       "      <td>2.231159e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model 1 Diff  Model 2 Diff  Model 3 Diff  Model 4 Diff  Model 5 Diff  \\\n",
       "count  1.158500e+04  1.158500e+04  1.158500e+04  1.158500e+04  1.158500e+04   \n",
       "mean  -1.071248e+04 -1.651190e+04 -1.003327e+04 -9.459277e+03 -1.264379e+04   \n",
       "std    1.970692e+05  1.974009e+05  1.962238e+05  1.969501e+05  1.979846e+05   \n",
       "min   -3.896860e+06 -4.081291e+06 -3.866715e+06 -3.827125e+06 -3.925216e+06   \n",
       "25%   -4.723497e+04 -5.164920e+04 -4.681198e+04 -4.630585e+04 -4.829316e+04   \n",
       "50%   -2.554371e+03 -6.355793e+03 -2.939206e+03 -1.364099e+03 -3.452520e+03   \n",
       "75%    4.084156e+04  3.663483e+04  4.189445e+04  4.201571e+04  3.891881e+04   \n",
       "max    2.665931e+06  2.558717e+06  2.613563e+06  2.739440e+06  2.599624e+06   \n",
       "\n",
       "       Model 6 Diff  Model 7 Diff  Model 8 Diff  Model 9 Diff  Model 10 Diff  \n",
       "count  1.158500e+04  1.158500e+04  1.158500e+04  1.158500e+04   1.158500e+04  \n",
       "mean  -1.145299e+04 -3.188869e+03 -5.163294e+03 -5.586760e+03   5.904763e+03  \n",
       "std    1.959908e+05  2.066466e+05  2.099215e+05  2.077299e+05   2.059482e+05  \n",
       "min   -4.015964e+06 -4.971180e+06 -4.790067e+06 -4.790068e+06  -4.500315e+06  \n",
       "25%   -4.767781e+04 -4.083493e+04 -4.173834e+04 -4.082184e+04  -3.374074e+04  \n",
       "50%   -3.034910e+03  1.904575e+03  2.072094e+03  2.730344e+03   9.930012e+03  \n",
       "75%    4.004456e+04  4.879335e+04  4.881912e+04  4.929825e+04   6.325047e+04  \n",
       "max    2.709411e+06  2.693534e+06  3.015724e+06  3.182957e+06   2.231159e+06  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.007594255150633928,\n",
       " 0.034407444944772395,\n",
       " 0.22646548409025372,\n",
       " 0.022501028044347643,\n",
       " 0.09559911771351595,\n",
       " 0.034889144045619026,\n",
       " 0.381061682404559,\n",
       " 0.004495723042812846,\n",
       " 0.10096806187135418,\n",
       " 0.09201805869213116]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np, numpy.random\n",
    "w1=np.random.dirichlet(np.ones(10),size=1)\n",
    "w1=list(w1[0])\n",
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "efed5421f1f26c8e8cb1daaf973ed6c60def92cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.09440770408188659\n",
      "Final score is:  0.1299319033440164\n",
      "Testing Cross Validation Error:  0.1299319033440164\n"
     ]
    }
   ],
   "source": [
    "# 6\n",
    "from lightgbm import LGBMRegressor\n",
    "import numpy as np\n",
    "model = LGBMRegressor(boosting_type='dart', max_depth=8, learning_rate=0.13, n_estimators=500,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = LGBMRegressor(boosting_type='dart', max_depth=8, learning_rate=0.13, n_estimators=500,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "newscore=cross_validation_function3(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "091622f5c452946c278c2a801dcf8f5947d8f0ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.09756882300621789\n",
      "Final score is:  0.1301227287454838\n",
      "Testing Cross Validation Error:  0.1301227287454838\n"
     ]
    }
   ],
   "source": [
    "# 7\n",
    "from lightgbm import LGBMRegressor\n",
    "import numpy as np\n",
    "model = LGBMRegressor(boosting_type='dart', max_depth=7, learning_rate=0.14, n_estimators=400,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = LGBMRegressor(boosting_type='dart', max_depth=7, learning_rate=0.14, n_estimators=400,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "newscore=cross_validation_function3(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "5171dbaaaf38e87dea6c733a8f8cc48d302ed5b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.09173034223345002\n",
      "Final score is:  0.1294838650847539\n",
      "Testing Cross Validation Error:  0.1294838650847539\n"
     ]
    }
   ],
   "source": [
    "# 12   ^^^^^  2   ^^^^^^\n",
    "from lightgbm import LGBMRegressor\n",
    "import numpy as np\n",
    "model = LGBMRegressor(boosting_type='dart', max_depth=9, learning_rate=0.19, n_estimators=400,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = LGBMRegressor(boosting_type='dart', max_depth=9, learning_rate=0.19, n_estimators=400,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "newscore=cross_validation_function(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "001825264f59b63784315dbccd3427f5d11c7e36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.08780665488601577\n",
      "Final score is:  0.1301254008919178\n",
      "Testing Cross Validation Error:  0.1301254008919178\n"
     ]
    }
   ],
   "source": [
    "# 11     ##########3##########\n",
    "from lightgbm import LGBMRegressor\n",
    "import numpy as np\n",
    "model = LGBMRegressor(boosting_type='dart', max_depth=8, learning_rate=0.24, n_estimators=350,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = LGBMRegressor(boosting_type='dart', max_depth=8, learning_rate=0.24, n_estimators=350,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "newscore=cross_validation_function3(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "75a3c21044eb236d603403acbe2677b3825461bb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "f4e447697c5e9fb4c7c78ff267ffefb467c840f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:116: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.09118468888695819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:116: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:116: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:116: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:116: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:116: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score is:  0.13037873681970596\n",
      "Testing Cross Validation Error:  0.13037873681970596\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "import numpy as np\n",
    "model = LGBMRegressor(num_iterations=900,boosting_type='dart', max_depth=7, learning_rate=0.09, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = LGBMRegressor(num_iterations=900,boosting_type='dart', max_depth=7, learning_rate=0.08, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "newscore=cross_validation_function3(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "ac38938b688facd40d751272eb343c308b871e83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.0910829674581461\n",
      "Final score is:  0.13003222743241366\n",
      "Testing Cross Validation Error:  0.13003222743241366\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = LGBMRegressor(boosting_type='dart', max_depth=8, learning_rate=0.13, n_estimators=600,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = LGBMRegressor(boosting_type='dart', max_depth=8, learning_rate=0.13, n_estimators=600,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "newscore=cross_validation_function3(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "1792c0376d87a1f57f1651949ee831e0edf6aedf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.09173034223345002\n",
      "Final score is:  0.1294838650847539\n",
      "Testing Cross Validation Error:  0.1294838650847539\n"
     ]
    }
   ],
   "source": [
    "# 12\n",
    "model = LGBMRegressor(boosting_type='dart', max_depth=9, learning_rate=0.19, n_estimators=400,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = LGBMRegressor(boosting_type='dart', max_depth=9, learning_rate=0.19, n_estimators=400,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "newscore=cross_validation_function3(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "92348750a88c989db338cac2801a6c2edd51e61d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.09440770408188659\n",
      "Final score is:  0.1299319033440164\n",
      "Testing Cross Validation Error:  0.1299319033440164\n"
     ]
    }
   ],
   "source": [
    "# 6\n",
    "model = LGBMRegressor(boosting_type='dart', max_depth=8, learning_rate=0.13, n_estimators=500,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = LGBMRegressor(boosting_type='dart', max_depth=8, learning_rate=0.13, n_estimators=500,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "newscore=cross_validation_function3(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "01d1df8dcde38152e1222b0c286ee44833af5721"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:116: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.09118468888695819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:116: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:116: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:116: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:116: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:116: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final score is:  0.1301376781265132\n",
      "Testing Cross Validation Error:  0.1301376781265132\n"
     ]
    }
   ],
   "source": [
    "# 4              ######4$$$$$$\n",
    "model = LGBMRegressor(boosting_type='dart',num_iterations=900 ,max_depth=7, learning_rate=0.09, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = LGBMRegressor(boosting_type='dart',num_iterations=900 ,max_depth=7, learning_rate=0.09, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "newscore=cross_validation_function3(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "0285605cd082017c42c86d127f047731da0780d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.0906421739064629\n",
      "Final score is:  0.12912559913782506\n",
      "Testing Cross Validation Error:  0.12912559913782506\n"
     ]
    }
   ],
   "source": [
    "# 25      %%%5%%%%\n",
    "\n",
    "model = LGBMRegressor(boosting_type='dart', num_leaves=29,min_data_in_leaf=15 ,max_depth=7, learning_rate=0.09, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = LGBMRegressor(boosting_type='dart', num_leaves=29,min_data_in_leaf=15 ,max_depth=7, learning_rate=0.09, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "newscore=cross_validation_function3(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "60ea53769356426471339f6c6694c70eb13dad84"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "655120c0e57bad0588b678c5dfeb270f3b2c1b5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.08639806154333846\n",
      "Final score is:  0.12946930176990257\n",
      "Testing Cross Validation Error:  0.12946930176990257\n"
     ]
    }
   ],
   "source": [
    "# 22     ######6$$$$$$$$$\n",
    "\n",
    "model = LGBMRegressor(boosting_type='dart', num_leaves=25, max_depth=7, learning_rate=0.13, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = LGBMRegressor(boosting_type='dart', num_leaves=25, max_depth=7, learning_rate=0.13, n_estimators=1000,objective='regression',metric='mape',tree_learner='serial',random_state=30, n_jobs=-1 )\n",
    "newscore=cross_validation_function3(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "18a05d82ec70eb2ad62816a1f7f7dca14fda597b"
   },
   "source": [
    "# Gradient Booster Final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "7e7a8f8ae474e652bc5ee069795e70a5c6ab99e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.07584326247482823\n",
      "Final score is:  0.133919734864522\n",
      "Testing Cross Validation Error:  0.133919734864522\n"
     ]
    }
   ],
   "source": [
    "# 16--Final Gradient Booster ALone   #####7#####\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score  \n",
    "model = ensemble.GradientBoostingRegressor(n_estimators= 300, max_depth=7,learning_rate=0.054 , loss= 'ls',random_state=30)\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = ensemble.GradientBoostingRegressor(n_estimators= 300, max_depth=7,learning_rate=0.054 , loss= 'ls',random_state=30)\n",
    "newscore=cross_validation_function3(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)\n",
    "\n",
    "\n",
    "              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7bfa55613da81b040fe2a641f8f55c6dc2a86296"
   },
   "source": [
    "# Final XGBoost MODEL :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "088c9868619a86e25f43775680f0207823d69e34"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.07091322221615406\n",
      "Final score is:  0.13619988841724287\n",
      "Testing Cross Validation Error:  0.13619988841724287\n"
     ]
    }
   ],
   "source": [
    "# Zillow 1.2\n",
    "model = XGBRegressor(max_depth=9,learning_rate=0.04, n_estimators=178,booster='gbtree',random_state=30)\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = XGBRegressor(max_depth=9,learning_rate=0.04, n_estimators=178,booster='gbtree',random_state=30)\n",
    "newscore=cross_validation_function3(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.06262514875825706\n",
      "Final score is:  0.13649872671587376\n",
      "Testing Cross Validation Error:  0.13649872671587376\n"
     ]
    }
   ],
   "source": [
    "# Zillow 1.3\n",
    "model = XGBRegressor(max_depth=8,learning_rate=0.1, n_estimators=200,booster='gbtree',random_state=30)\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = XGBRegressor(max_depth=8,learning_rate=0.1, n_estimators=200,booster='gbtree',random_state=30)\n",
    "newscore=cross_validation_function3(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.09372542563129925\n",
      "Final score is:  0.13494654749486582\n",
      "Testing Cross Validation Error:  0.13494654749486582\n"
     ]
    }
   ],
   "source": [
    "# Zillow 1.4\n",
    "model = XGBRegressor(max_depth=8,learning_rate=0.04, n_estimators=100,booster='gbtree',random_state=30)\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = XGBRegressor(max_depth=8,learning_rate=0.04, n_estimators=100,booster='gbtree',random_state=30)\n",
    "newscore=cross_validation_function3(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.06381928266400659\n",
      "Final score is:  0.13411487443671416\n",
      "Testing Cross Validation Error:  0.13411487443671416\n"
     ]
    }
   ],
   "source": [
    "# Zillow 1.4$   #####8#####\n",
    "model = XGBRegressor(max_depth=8,learning_rate=0.04, n_estimators=500,booster='gbtree',random_state=30)\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = XGBRegressor(max_depth=8,learning_rate=0.04, n_estimators=500,booster='gbtree',random_state=30)\n",
    "newscore=cross_validation_function3(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.07988238944609445\n",
      "Final score is:  0.13469952012166053\n",
      "Testing Cross Validation Error:  0.13469952012166053\n"
     ]
    }
   ],
   "source": [
    "# Zillow 1.4$##   #####9#####\n",
    "model = XGBRegressor(max_depth=8,learning_rate=0.081, n_estimators=100,booster='gbtree',random_state=30)\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = XGBRegressor(max_depth=8,learning_rate=0.081, n_estimators=100,booster='gbtree',random_state=30)\n",
    "newscore=cross_validation_function3(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest FINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.05291163508976431\n",
      "Final score is:  0.14433978908042905\n",
      "Testing Cross Validation Error:  0.14433978908042905\n"
     ]
    }
   ],
   "source": [
    "# Zillow -----> #####10#####\n",
    "model = RandomForestRegressor(max_depth=18, random_state=30,n_estimators=91)\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = RandomForestRegressor(max_depth=18, random_state=30,n_estimators=91)\n",
    "newscore=cross_validation_function3(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error :  0.1184269569098208\n",
      "Final score is:  0.1725050602189087\n",
      "Testing Cross Validation Error:  0.1725050602189087\n"
     ]
    }
   ],
   "source": [
    "# Zillow -----> 0.1725\n",
    "model = RandomForestRegressor(max_depth=9, random_state=30,n_estimators=500)\n",
    "model.fit(X,y.values.ravel())\n",
    "y_pred=model.predict(X)\n",
    "y_true=pd.Series(y.iloc[:,0])\n",
    "print(\"Training Error : \",np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "model = RandomForestRegressor(max_depth=6, random_state=30,n_estimators=78)\n",
    "newscore=cross_validation_function3(X,y,model,5)\n",
    "print(\"Testing Cross Validation Error: \",newscore)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e5cb4460c25090d25387d2f47d2e024c87983bb8"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "from xgboost import XGBRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b71c68951f154d896eb3dcfee11140f976d4a638"
   },
   "outputs": [],
   "source": [
    "NN_model = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = X.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b8ed37cf582ff6edbd477cbb8918bc460483e5f5"
   },
   "outputs": [],
   "source": [
    "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "302f0d8203cdb295bb1e9e64b4a5b969a14ec916"
   },
   "outputs": [],
   "source": [
    "NN_model.fit(X,y, epochs=500, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5451fd04e79fa4205063fbfec2c0a57c28aa92d6"
   },
   "outputs": [],
   "source": [
    "# wights_file = 'Weights-00500--141345.79756.hdf5' # choose the best checkpoint \n",
    "# NN_model.load_weights(wights_file) # load it\n",
    "# NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "y_pred=NN_model.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ed347a8adf6edc2db9760672395611335d9120ff"
   },
   "outputs": [],
   "source": [
    "temp=pd.DataFrame(y_pred)\n",
    "temp[2]=y_true\n",
    "temp[3]=temp[0]-temp[2]\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c5ccbd30564657c3790a7aa981dd4dc5c4058706"
   },
   "outputs": [],
   "source": [
    "y_true=y\n",
    "print(np.mean(np.abs((y_true - y_pred) / y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "59441f3eb1cf947f4243c03b154a38f1cb61a1f5"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "knn = KNeighborsRegressor()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred=knn.predict(X_test)\n",
    "y_true=y_test\n",
    "print(np.mean(np.abs((y_true - y_pred) / y_true)) )\n",
    "output=pd.DataFrame(data=y_true)\n",
    "output[\"KNN_pred\"]=y_pred\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9476503f57bebaed5912c59392fc6d9f04d77a14"
   },
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "853a2a0db34df286d856a02a4e73b3fbbba92b4a"
   },
   "outputs": [],
   "source": [
    "def cross_validation_function(X,y,model,fold):\n",
    "    size=int(len(X)/fold)\n",
    "    l=0\n",
    "    u=size\n",
    "    scores=[]\n",
    "    for f in range(fold):\n",
    "        print(\"l =\",l,\"u =\",u,\"\")\n",
    "        dfxtest=X.iloc[l:u,:]\n",
    "        dfytest=y.iloc[l:u,:]\n",
    "        dfxtrain=X.drop(X.iloc[l:u].index,axis=0)\n",
    "        dfytrain=y.drop(X.iloc[l:u].index,axis=0)\n",
    "        model.fit(dfxtrain,dfytrain)\n",
    "        y_pred=model.predict(dfxtest)\n",
    "        y_true=dfytest\n",
    "#         print(y_true)\n",
    "#         print(y_pred)\n",
    "        scores.append(np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "        print(\"        FOLD \",f)\n",
    "        print(\"        --> Score :\", (np.mean(np.abs((y_true - y_pred) / y_true))))\n",
    "        l=l+size\n",
    "        u=u+size\n",
    "    print(\"Final score is: \",np.mean(scores))\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8d0192b07d3e2de0eaebf3ab8d11492a39e85826"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "for n in range(1,30):\n",
    "    knn = KNeighborsRegressor(n_neighbors=n,weights=\"distance\")\n",
    "    print(\"N=\",n)\n",
    "    cross_validation_function(X,y,knn,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "637e20d328d1a844b74de66678dee604c336fefe"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "for n in range(1,30):\n",
    "    knn = KNeighborsRegressor(n_neighbors=n,weights=\"distance\")\n",
    "    print(\"N=\",n)\n",
    "    cross_validation_function(X,y,knn,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2005ccdd6a65c06d7ac348f2562213b8843541e2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0bc9e5a54faa16fc0a087ebf6de9908df90f8894"
   },
   "source": [
    "# Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a01254ec496a14ebd94c8325cc1da0cbf57ae32"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3ff3805feb7119529928718987c090d61aab188a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a9b3b15e94ebc3c77ebe25eecfeaa00ba34a7b89"
   },
   "outputs": [],
   "source": [
    "def cross_validation_function2(X,y,model,fold):\n",
    "    size=int(len(X)/fold)\n",
    "    l=0\n",
    "    u=size\n",
    "    scores=[]\n",
    "    for f in range(fold):\n",
    "#         print(\"l =\",l,\"u =\",u,\"\")\n",
    "        dfxtest=X.iloc[l:u,:]\n",
    "        dfytest=y.iloc[l:u,:]\n",
    "        dfxtrain=X.drop(X.iloc[l:u].index,axis=0)\n",
    "        dfytrain=y.drop(X.iloc[l:u].index,axis=0)\n",
    "        model.fit(dfxtrain,dfytrain)\n",
    "        y_pred=model.predict(dfxtest)\n",
    "        y_true=pd.Series(dfytest.iloc[:,0])\n",
    "#         pd.Series(y.iloc[:,0])\n",
    "#         print(y_true)\n",
    "#         print(y_pred)\n",
    "        scores.append(np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "        print(\"        FOLD \",f)\n",
    "        print(\"        --> Score :\", (np.mean(np.abs((y_true - y_pred) / y_true))))\n",
    "        l=l+size\n",
    "        u=u+size\n",
    "    print(\"Final score is: \",np.mean(scores))\n",
    "    return np.mean(scores)\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c2a5a6206ce65afe73525106d25e40957c82de22"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "min=1\n",
    "sc=[]\n",
    "for d in range(1,30):\n",
    "    tree = DecisionTreeRegressor(max_depth=d,criterion='mae')\n",
    "    print(\"Depth =\",d)\n",
    "    newscore=cross_validation_function2(X,y,tree,5)\n",
    "    sc.append(newscore)\n",
    "    if(newscore<min):\n",
    "        min=newscore\n",
    "        print(\"Min CHANGED TO : \",min,\" at d =\",d)\n",
    "print(min(sc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2ec21acd8288da1eed3b59f586088320df3ec57c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5908f2b5b318bd826f8153cce55de838e5eac736"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5f07f803c5d8d1c599209e88b747d9daefbadff3"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "sc=[]\n",
    "min=1\n",
    "for d in range(2,30):\n",
    "    for nest in range(10,500,10):\n",
    "        forest = RandomForestRegressor(max_depth=d, random_state=30,n_estimators=nest)\n",
    "        print(\"N Estimators is : \",nest)\n",
    "        print(\"Depth =\",d)\n",
    "        newscore=cross_validation_function3(X,y,forest,5)\n",
    "        sc.append(newscore)\n",
    "        if(newscore<min):\n",
    "            min=newscore\n",
    "            print(\"Min CHANGED TO : \",min,\" at d =\",d,\" and n est = \",nest)\n",
    "print(min(sc))\n",
    "    # print(regr.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "96d13a37ed36c36d83afc4d9f689a57ec959e376"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "73c030d9f78f2d53c5eb4ed0de3539b4530a32b4"
   },
   "source": [
    "Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "544d62bf6d3559dc044037b4f2cc42a439588d9a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc5049f9f742c0f9cbfe845ed155dc8d483c06b9"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "for d in range(1,30):\n",
    "    for nest in range(10,200,10):\n",
    "    forest = RandomForestRegressor(max_depth=d, random_state=30,n_estimators=100)\n",
    "    print(\"Depth =\",d)\n",
    "    cross_validation_function(X,y,forest,5)\n",
    "# print(regr.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b2b7ceecd1e743daedcd6cd40c26fa1fd2d6f41d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dd5064c5fc8fa1a7cc832d00b6714393a8751e12"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a597b17ffe52e83b7948c2f3420fbb83c6518bc4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "00e2c63ecaf915e6426bebae20bf8601f2a44ac6"
   },
   "source": [
    "# Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fd22230c78a1ed2adecb7409c82af8f8e64324d1"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "60dac170723d68e28b24aee3b3732bcc33952c97"
   },
   "outputs": [],
   "source": [
    "def cross_validation_function3(X,y,model,fold):\n",
    "    size=int(len(X)/fold)\n",
    "    l=0\n",
    "    u=size\n",
    "    scores=[]\n",
    "    for f in range(fold):\n",
    "#         print(\"l =\",l,\"u =\",u,\"\")\n",
    "        dfxtest=X.iloc[l:u,:]\n",
    "        dfytest=y.iloc[l:u,:]\n",
    "        dfxtrain=X.drop(X.iloc[l:u].index,axis=0)\n",
    "        dfytrain=y.drop(X.iloc[l:u].index,axis=0)\n",
    "        model.fit(dfxtrain,dfytrain.values.ravel())\n",
    "        y_pred=model.predict(dfxtest)\n",
    "        y_true=pd.Series(dfytest.iloc[:,0])\n",
    "#         pd.Series(y.iloc[:,0])\n",
    "#         print(y_true)\n",
    "#         print(y_pred)\n",
    "        scores.append(np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "        print(\"        FOLD \",f)\n",
    "        print(\"        --> Score :\", (np.mean(np.abs((y_true - y_pred) / y_true))))\n",
    "        l=l+size\n",
    "        u=u+size\n",
    "    print(\"Final score is: \",np.mean(scores))\n",
    "    return np.mean(scores)\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c641b2f7bcdefd371a660c3ca94f3a4e4b22bff6"
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "sc=[]\n",
    "min=1\n",
    "for nest in range(10,500,10):\n",
    "    for d in range(5,25):\n",
    "        for l in np.arange(0.01,0.5,0.005):\n",
    "            clf = ensemble.GradientBoostingRegressor(n_estimators= nest, max_depth=d,learning_rate=l , loss= 'ls',random_state=30)\n",
    "            print(\"N Estimators is : \",nest)\n",
    "            print(\"Depth =\",d)\n",
    "            newscore=cross_validation_function3(X,y,clf,5)\n",
    "            sc.append(newscore)\n",
    "            if(newscore<min):\n",
    "                min=newscore\n",
    "                print(\"Min CHANGED TO : \",min,\" at d =\",d,\" and n est = \",nest,\"l =\",l)\n",
    "# print(min(sc))\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aec7826cc10a762e4dad0753e885a077a1e34d5e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "00dcae7c97df152a2a1ec1489ebdb7ecfd55d5ca"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bf6b79ac08628ae47cb79064b492e0cbe6957630"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "938a4a43c8b53d37e9c62cb19652265aa871a4f3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3c7884218554b5eb1b6b440e43e62dfeb380307a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8aa58ec1c52068da0c764df2dfe3328e55591859"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c5d31714381238891bed628c87324579ece72303"
   },
   "outputs": [],
   "source": [
    "def cross_validation_function3(X,y,model,fold):\n",
    "    size=int(len(X)/fold)\n",
    "    l=0\n",
    "    u=size\n",
    "    scores=[]\n",
    "    for f in range(fold):\n",
    "#         print(\"l =\",l,\"u =\",u,\"\")\n",
    "        dfxtest=X.iloc[l:u,:]\n",
    "        dfytest=y.iloc[l:u,:]\n",
    "        dfxtrain=X.drop(X.iloc[l:u].index,axis=0)\n",
    "        dfytrain=y.drop(X.iloc[l:u].index,axis=0)\n",
    "        model.fit(dfxtrain,dfytrain.values.ravel())\n",
    "        y_pred=model.predict(dfxtest)\n",
    "        y_true=pd.Series(dfytest.iloc[:,0])\n",
    "#         pd.Series(y.iloc[:,0])\n",
    "#         print(y_true)\n",
    "#         print(y_pred)\n",
    "        scores.append(np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "#         print(\"        FOLD \",f)\n",
    "#         print(\"        --> Score :\", (np.mean(np.abs((y_true - y_pred) / y_true))))\n",
    "        l=l+size\n",
    "        u=u+size\n",
    "    print(\"Final score is: \",np.mean(scores))\n",
    "    return np.mean(scores)\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "20632f180c3aa5db3fae16bb6986660c1d6be575"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "sc=[]\n",
    "min=1\n",
    "booster=['gbtree','gblinear','dart']\n",
    "\n",
    "for nest in range(1,100,1):\n",
    "    for b in booster:\n",
    "        for l in np.arange(0.01,0.8,0.005):\n",
    "            for d in range(3,30):\n",
    "                xgbreg = XGBRegressor(max_depth=d,learning_rate=l, n_estimators=nest,booster=b,random_state=30)\n",
    "                print(\"N Estimators is : \",nest)\n",
    "                print(\"Depth =\",d)\n",
    "                print(\"Learning Rate: \",l)\n",
    "                print(\"Booster : \",b)\n",
    "                newscore=cross_validation_function3(X,y,xgbreg,5)\n",
    "                sc.append(newscore)\n",
    "                if(newscore<min):\n",
    "                    min=newscore\n",
    "                    print(\"Min CHANGED TO : \",min,\" at d =\",d,\" and n est = \",nest,\"l =\",l,\" b = \",b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "41c3bc46364a13c4a3ba9d204fc14848b226be67"
   },
   "outputs": [],
   "source": [
    "max_depth = m,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "60a5e7512eca61a512ed83f7ac460cc485d0b247"
   },
   "outputs": [],
   "source": [
    "for d in range(1,10):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8e20b24f07c8d34bd23e7701c6b2b883a606ddd2"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "sc=[]\n",
    "min=1\n",
    "booster=['gbtree','dart']\n",
    "for d in range(7,10):\n",
    "    for nest in range(19,50,1):\n",
    "        for b in booster:\n",
    "            for l in np.arange(0.01,0.9,0.01):\n",
    "                xgbreg = XGBRegressor(max_depth=d,learning_rate=l, n_estimators=nest,booster=b,random_state=30)\n",
    "                print(\"N Estimators is : \",nest)\n",
    "                print(\"Depth =\",d)\n",
    "                print(\"Learning Rate: \",l)\n",
    "                print(\"Booster : \",b)\n",
    "                newscore=cross_validation_function3(X,y,xgbreg,5)\n",
    "                sc.append(newscore)\n",
    "                if(newscore<min):\n",
    "                    min=newscore\n",
    "                    print(\"Min CHANGED TO : \",min,\" at d =\",d,\" and n est = \",nest,\"l =\",l,\" b = \",b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ebf4b15da867bbbcc1a0c3fe473d329d7a34845f"
   },
   "outputs": [],
   "source": [
    "def cross_validation_function3(X,y,model,fold):\n",
    "    size=int(len(X)/fold)\n",
    "    l=0\n",
    "    u=size\n",
    "    scores=[]\n",
    "    for f in range(fold):\n",
    "#         print(\"l =\",l,\"u =\",u,\"\")\n",
    "        dfxtest=X.iloc[l:u,:]\n",
    "        dfytest=y.iloc[l:u,:]\n",
    "        dfxtrain=X.drop(X.iloc[l:u].index,axis=0)\n",
    "        dfytrain=y.drop(X.iloc[l:u].index,axis=0)\n",
    "        model.fit(dfxtrain,dfytrain.values.ravel())\n",
    "        y_pred=model.predict(dfxtest)\n",
    "        y_true=pd.Series(dfytest.iloc[:,0])\n",
    "#         pd.Series(y.iloc[:,0])\n",
    "#         print(y_true)\n",
    "#         print(y_pred)\n",
    "        scores.append(np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "#         print(\"        FOLD \",f)\n",
    "#         print(\"        --> Score :\", (np.mean(np.abs((y_true - y_pred) / y_true))))\n",
    "        l=l+size\n",
    "        u=u+size\n",
    "    print(\"Final score is: \",np.mean(scores))\n",
    "    return np.mean(scores)\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "26e0e6b880bbc11eb772e7e7a7bd0bf5c5b8dd8a"
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "sc=[]\n",
    "min=1\n",
    "\n",
    "for nest in range(100,1000,70):\n",
    "    for d in range(3,25):\n",
    "        for l in np.arange(0.1,0.9,0.1):\n",
    "            clf = ensemble.GradientBoostingRegressor(n_estimators= nest, max_depth=d,learning_rate=l , loss= 'ls',random_state=30)\n",
    "            print(\"N Estimators is : \",nest)\n",
    "            print(\"Depth =\",d)\n",
    "            newscore=cross_validation_function3(X,y,clf,5)\n",
    "            sc.append(newscore)\n",
    "            if(newscore<min):\n",
    "                min=newscore\n",
    "                print(\"Min CHANGED TO : \",min,\" at d =\",d,\" and n est = \",nest,\"l =\",l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ffbbe29a0681b74d02738ae624c2739c19e392c3"
   },
   "outputs": [],
   "source": [
    "\n",
    "# This is test for Zillow 1.1 d=7 nest=??(200)  and l= 0.04\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "sc=[]\n",
    "min=1\n",
    "# for d in range(1,30):\n",
    "for n in range(100,1000,50):\n",
    "#     for l in np.arange(0.01,0.9,0.005):\n",
    "    clf = ensemble.GradientBoostingRegressor(n_estimators= n, max_depth=7,learning_rate=0.04 , loss= 'ls',random_state=30)\n",
    "    print(\"N Estimators is : \",n)\n",
    "#     print(\"learning rate  =\",l)\n",
    "    newscore=cross_validation_function3(X,y,clf,5)\n",
    "    sc.append(newscore)\n",
    "    if(newscore<min):\n",
    "        min=newscore\n",
    "        print(\"Min CHANGED TO : \",min,\" and n est = \",n)\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "#   you need to loop for l --> learning rate too "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "82b54865ae1e3d4399de69f39b17ac2345569e1f"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "sc=[]\n",
    "min=1\n",
    "for d in range(2,30):\n",
    "    for nest in range(100,1000,50):\n",
    "        forest = RandomForestRegressor(max_depth=d, random_state=30,n_estimators=nest)\n",
    "        print(\"N Estimators is : \",nest)\n",
    "        print(\"Depth =\",d)\n",
    "        newscore=cross_validation_function3(X,y,forest,5)\n",
    "        sc.append(newscore)\n",
    "        if(newscore<min):\n",
    "            min=newscore\n",
    "            print(\"Min CHANGED TO : \",min,\" at d =\",d,\" and n est = \",nest)\n",
    "print(min(sc))\n",
    "    # print(regr.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d23205f03ec97bab42e38233f7b2130a075291a1"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "# gammas = [0.001, 0.01, 0.1, 1]\n",
    "gammas = [0.1, 1]\n",
    "\n",
    "ds =[3,4,5,6,7]\n",
    "sc=[]\n",
    "min=1\n",
    "for d in ds:\n",
    "    for g in gammas:\n",
    "        for c in Cs:\n",
    "            model = SVR(kernel='rbf', degree=d, gamma=g, coef0=0.0, tol=0.001, C=c, epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1)\n",
    "        #     xgbreg = XGBRegressor(max_depth=d,learning_rate=l, n_estimators=nest,booster='gbtree',random_state=30)\n",
    "        #     print(\"N Estimators is : \",nest)\n",
    "            print(\"Degree =\",d)\n",
    "            print(\"Gamma: \",g)\n",
    "            print(\"C : \",c)\n",
    "            newscore=cross_validation_function3(X,y,model,5)\n",
    "            sc.append(newscore)\n",
    "            if(newscore<min):\n",
    "                min=newscore\n",
    "                print(\"Min CHANGED TO : \",min,\" at Degree =\",d,\"Gamma = \",g,\"C = \",c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fa5c730b3b1716947994475fd6a6a3027c3db51f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "00d3f0c1bf414284e83cc8982ccefd7f55ab3f11"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "60a35c1d3632f1aa604f483c6a30e0352f0a5215"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0da148ae4d822b9d5735aacdddadfb717477bb9e"
   },
   "outputs": [],
   "source": [
    "def cross_validation_function3(X,y,model,fold):\n",
    "    size=int(len(X)/fold)\n",
    "    l=0\n",
    "    u=size\n",
    "    scores=[]\n",
    "    for f in range(fold):\n",
    "#         print(\"l =\",l,\"u =\",u,\"\")\n",
    "        dfxtest=X.iloc[l:u,:]\n",
    "        dfytest=y.iloc[l:u,:]\n",
    "        dfxtrain=X.drop(X.iloc[l:u].index,axis=0)\n",
    "        dfytrain=y.drop(X.iloc[l:u].index,axis=0)\n",
    "        model.fit(dfxtrain,dfytrain.values.ravel())\n",
    "        y_pred=model.predict(dfxtest)\n",
    "        y_true=pd.Series(dfytest.iloc[:,0])\n",
    "#         pd.Series(y.iloc[:,0])\n",
    "#         print(y_true)\n",
    "#         print(y_pred)\n",
    "        scores.append(np.mean(np.abs((y_true - y_pred) / y_true)))\n",
    "#         print(\"        FOLD \",f)\n",
    "#         print(\"        --> Score :\", (np.mean(np.abs((y_true - y_pred) / y_true))))\n",
    "        l=l+size\n",
    "        u=u+size\n",
    "    print(\"Final score is: \",np.mean(scores))\n",
    "    return np.mean(scores)\n",
    "      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bd7d4cf9c3bad47541dd15a33e5e95c41432e602"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "30dd84d57c3c2a7ca72a1c99990e607ebe7dc75a"
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "import numpy as np\n",
    "boosting_type_set1=['gbdt','gbrt','dart']\n",
    "boosting_type_set2=['gbdt']\n",
    "m=20\n",
    "n=31\n",
    "min_data_in_leafset=[15,20,25]\n",
    "tree_learner_set =['serial','feature','data','voting']\n",
    "sc=[]\n",
    "min = 1\n",
    "for nest in range(900,100,-200):\n",
    "    for d in range(7,10):\n",
    "        for l in np.arange(0.005,0.22,0.002):\n",
    "            for iter in range(200,10000,500):\n",
    "                for b in boosting_type_set2:\n",
    "                    for m in min_data_in_leafset:\n",
    "                        for n in [21,31,41]:\n",
    "#                 for n in range(25,48,4):\n",
    "#                     for m in range(5,30,5):\n",
    "#                 for t in tree_learner_set:\n",
    "                            lgbm = LGBMRegressor(num_iterations=iter,boosting_type=b, num_leaves=n, max_depth=d, learning_rate=l, n_estimators=nest,objective='regression',metric='mape',tree_learner='serial',min_data_in_leaf=m,random_state=30, n_jobs=-1 )\n",
    "                            print(\"N Estimators is : \",nest)\n",
    "                            print(\"Depth =\",d)\n",
    "                            print(\"Learning Rate: \",l)\n",
    "#                             print(\"b = \",b)\n",
    "                            print(\"NO of iterations :\",iter)\n",
    "                            print(\"no of leaves is :\",n)\n",
    "                            print(\"minimum data in leaf =\",m)\n",
    "            #                     print(\"tree learner set is : \",t)\n",
    "\n",
    "                            print(\"Booster : \",b)\n",
    "                            newscore=cross_validation_function3(X,y,lgbm,5)\n",
    "                            print(\"\\n\\n\")\n",
    "                            sc.append(newscore)\n",
    "                            if(newscore<min):\n",
    "                                min=newscore\n",
    "                #                 print(\"Min CHANGED TO : \",min,\"AND  n est = \",nest,\"l = \",l)\n",
    "                                print(\"Min CHANGED TO : \",min,\" at d =\",d,\" and n est = \",nest,\"l =\",l,\"b = \",b,\"no of iterations = \",iter,\"n = \",n,\"m = \",m)\n",
    "                                print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "_uuid": "f1c8488cf047410912a97d2eab6d00f39ea1afed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.09090909090909091,\n",
       " 0.09090909090909091,\n",
       " 0.09090909090909091,\n",
       " 0.09090909090909091,\n",
       " 0.09090909090909091,\n",
       " 0.09090909090909091,\n",
       " 0.09090909090909091,\n",
       " 0.09090909090909091,\n",
       " 0.09090909090909091,\n",
       " 0.09090909090909091,\n",
       " 0.09090909090909091]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w=[1/11]*11\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
